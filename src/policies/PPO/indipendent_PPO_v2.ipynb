{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3cd819",
   "metadata": {},
   "source": [
    "# My custom env\n",
    "\n",
    "Here I can easily fix what is non conform to Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d632f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from pettingzoo import ParallelEnv\n",
    "import pygame \n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "SPRITES_DIR = \"./sprites\"\n",
    "\n",
    "\n",
    "class MyGridWorld(ParallelEnv):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"name\": \"custom_grid_v0\"}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=15):\n",
    "        if grid_size<8:\n",
    "            print(\"Error, need to insert a grid size greater or equal to 8\")\n",
    "        self.grid_size = grid_size\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        ######## Agents, fixed components, and forbidden positions\n",
    "        self.possible_agents = [\"agent1\", \"agent2\"]\n",
    "        self.agents = self.possible_agents[:]\n",
    "        self.gate_open = False\n",
    "\n",
    "        self.fixed_components = {\n",
    "            \"button\":  {\"pos\": np.array([self.grid_size//2+2, 1+3+2]), \"file\": \"button.png\"},\n",
    "            \"gate_open\":  {\"pos\": np.array([self.grid_size//2, 1+3]), \"file\": \"gate_open.png\"},\n",
    "            \"gate_close\":  {\"pos\": np.array([self.grid_size//2, 1+3]), \"file\": \"gate_close.png\"}   \n",
    "        }\n",
    "        self.button_pos = self.fixed_components[\"button\"][\"pos\"]\n",
    "        self.gate_pos = self.fixed_components[\"gate_open\"][\"pos\"] \n",
    "        self.target_final_pos = self.gate_pos+[0, -1]\n",
    "\n",
    "        self.x_range = (1, self.grid_size-1-1)\n",
    "        self.y_range = (1+3+1, self.grid_size-1-1)\n",
    "        self.forbidden_position = {tuple(self.button_pos)}    \n",
    "\n",
    "        self.max_cycles = 100\n",
    "        self.current_cycles = 0\n",
    "        ######## Pygame graphic configuration \n",
    "        self.window_size = 810\n",
    "        self.cell_size = self.window_size // self.grid_size\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "        # Walls\n",
    "        self.grid_map = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.grid_map[0, :] = 1\n",
    "        self.grid_map[:, 0] = 1\n",
    "        self.grid_map[-1, :] = 1\n",
    "        self.grid_map[:, -1] = 1\n",
    "        self.grid_map[ :, 1+3] = 1\n",
    "\n",
    "        # Sprites \n",
    "        self.agent_sprites = {}\n",
    "        self.component_sprites = {}\n",
    "\n",
    "        ######## Action space and observation space\n",
    "        # Five possible actions in each grid: stay(0), up(1), down(2), left(3), right(4)\n",
    "        self.action_spaces = {a: spaces.Discrete(5) for a in self.possible_agents}\n",
    "\n",
    "        OBSERVATION_DIM = 2*(len(self.agents)-1)+2*2+1\n",
    "        self.observation_spaces = {\n",
    "            a: spaces.Box(low=-(self.grid_size-1), high=self.grid_size-1, shape=(OBSERVATION_DIM,), dtype=np.float32) \n",
    "            for a in self.possible_agents\n",
    "        }\n",
    "        self.state_spaces = {a: None for a in self.possible_agents}\n",
    "\n",
    "    '''\n",
    "    Step in the environment\n",
    "    '''\n",
    "    def step(self, actions):\n",
    "        if not self.agents: return {}, {}, {}, {}, {}\n",
    "        self.current_cycles += 1\n",
    "        \n",
    "        rewards = {a: 0 for a in self.agents}\n",
    "\n",
    "        terminations = {a: False for a in self.agents}\n",
    "        truncations = {a: False for a in self.agents}\n",
    "        infos = {a: {} for a in self.agents}\n",
    "        \n",
    "        desired_positions = {}      \n",
    "        button_pressed = False\n",
    "        agents_desire_gate = []\n",
    "        for agent, action in actions.items():\n",
    "            current_pos = self.agent_positions[agent].copy()\n",
    "            target_pos = current_pos.copy()\n",
    "\n",
    "            if action == 1: target_pos[1] -= 1 \n",
    "            elif action == 2: target_pos[1] += 1\n",
    "            elif action == 3: target_pos[0] -= 1\n",
    "            elif action == 4: target_pos[0] += 1\n",
    "\n",
    "            # Monitor button, gate and walls\n",
    "            is_wall = self.grid_map[target_pos[0], target_pos[1]] == 1\n",
    "            is_gate = (target_pos == self.gate_pos).all()\n",
    "            is_button = (target_pos == self.button_pos).all()\n",
    "            \n",
    "            if is_button:\n",
    "                button_pressed = True\n",
    "            if is_gate:\n",
    "                agents_desire_gate.append((agent, current_pos))\n",
    "            \n",
    "            if is_wall and not is_gate:\n",
    "                desired_positions[agent] = current_pos \n",
    "            else:\n",
    "                desired_positions[agent] = target_pos\n",
    "                        \n",
    "        # If gate was open remove a wall, if gate was closed update the position of those who wanted to cross it\n",
    "        self.gate_open = button_pressed\n",
    "        if self.gate_open:\n",
    "            self.grid_map[self.gate_pos[0], self.gate_pos[1]] = 0\n",
    "        else:\n",
    "            self.grid_map[self.gate_pos[0], self.gate_pos[1]] = 1\n",
    "            for a in agents_desire_gate:\n",
    "                agent = a[0]\n",
    "                current_pos = a[1]\n",
    "                desired_positions[agent] = current_pos \n",
    "\n",
    "        # Check for conflicts (more than one agents have the same desired position)\n",
    "        final_positions = self.agent_positions.copy()\n",
    "        target_counts = defaultdict(list)         # Key: tuple(x, y) of desired positions, Value: list of agents desiring it\n",
    "        for agent, pos in desired_positions.items():\n",
    "            pos_tuple = tuple(pos)\n",
    "            target_counts[pos_tuple].append(agent)\n",
    "\n",
    "        # Solve eventual conflicts\n",
    "        for pos_tuple, agents_at_target in target_counts.items():      \n",
    "            # Case 1: no contended position\n",
    "            if len(agents_at_target) == 1:\n",
    "                agent = agents_at_target[0]\n",
    "                final_positions[agent] = desired_positions[agent]\n",
    "            \n",
    "            # Case 2: contended position\n",
    "            else:\n",
    "                one_agent_already_here_not_moving = None\n",
    "                for agent in agents_at_target:\n",
    "                    if tuple(self.agent_positions[agent]) == pos_tuple:\n",
    "                        one_agent_already_here_not_moving = agent\n",
    "                        break\n",
    "                \n",
    "                winning_agent = one_agent_already_here_not_moving if one_agent_already_here_not_moving else random.choice(agents_at_target)\n",
    "                final_positions[winning_agent] = desired_positions[winning_agent]\n",
    "                \n",
    "                agents_at_target.remove(winning_agent)\n",
    "                for losing_agent in agents_at_target[:]:\n",
    "                    final_positions[losing_agent] = self.agent_positions[losing_agent] \n",
    "        self.agent_positions = final_positions\n",
    "\n",
    "        # Negative reward if an agent is on the bottom area and is not pressing the button\n",
    "        agents_upper_area = 0\n",
    "        for a, pos in self.agent_positions.items():\n",
    "            dist_target = np.linalg.norm(pos - self.target_final_pos)\n",
    "            if pos[1]<4:                            # Agent on upper area\n",
    "                rewards[a] = +0.5\n",
    "                agents_upper_area+=1\n",
    "            elif (pos == self.button_pos).all():    # Agent on button\n",
    "                rewards[a] += 0.3     \n",
    "                rewards[a] -= (dist_target * 0.05)\n",
    "            else:                                   # Agent somewhere else on the grid\n",
    "                rewards[a] -= (dist_target * 0.05)\n",
    "\n",
    "       \n",
    "        if agents_upper_area == len(self.agents)-1:\n",
    "            rewards = {a: +100 for a in self.agents}\n",
    "            terminations = {a: True for a in self.agents}\n",
    "        if self.current_cycles >= self.max_cycles:\n",
    "            truncations= {a: True for a in self.agents}\n",
    "            \n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        final_obs = self.gather_observations()\n",
    "        self.agents = [a for a in self.agents if not terminations[a]]\n",
    "\n",
    "        return final_obs, rewards, terminations, truncations, infos\n",
    "   \n",
    "    # Boilerplate PettingZoo\n",
    "    def observation_space(self, agent): return self.observation_spaces[agent]\n",
    "    def action_space(self, agent): return self.action_spaces[agent]\n",
    "\n",
    "    '''\n",
    "    Determines initial condition of the simulation\n",
    "    '''\n",
    "\n",
    "    def generate_valid_position(self):\n",
    "        while True:\n",
    "            x = np.random.randint(self.x_range[0], self.x_range[1])\n",
    "            y = np.random.randint(self.y_range[0], self.y_range[1])\n",
    "            new_position = tuple((x, y))\n",
    "\n",
    "            if new_position not in self.forbidden_position:\n",
    "                return new_position\n",
    "            \n",
    "    def generate_set_initial_positions(self):\n",
    "        set_initial_positions = set()\n",
    "        while len(set_initial_positions)<len(self.possible_agents):\n",
    "            new_pos = self.generate_valid_position()\n",
    "            set_initial_positions.add(new_pos)\n",
    "        return set_initial_positions\n",
    "    \n",
    "    def generate_test_values(self, agent_num):\n",
    "        if agent_num==1:\n",
    "            return[7, 9]\n",
    "        else:\n",
    "            return [9,13]\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.agents = self.possible_agents[:]\n",
    "        set_initial_positions = list(self.generate_set_initial_positions())\n",
    "        self.current_cycles = 0\n",
    "\n",
    "        self.agent_positions = {\n",
    "            \"agent1\": np.array(set_initial_positions[0]),\n",
    "            \"agent2\": np.array(set_initial_positions[1])\n",
    "        }\n",
    "        \n",
    "        # To visualize the reset position if \"human\" mode on\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()         \n",
    "\n",
    "        return self.gather_observations(), {a: {} for a in self.agents}\n",
    "    \n",
    "    '''\n",
    "    Observation: [my_cur_pos, (other_cur) x number of other agents, button_pos, gate_pos, gate_open (1|0)]    '''\n",
    "    def gather_observations(self):\n",
    "        gate_status_info = np.array([int(self.gate_open)], dtype=np.int32)\n",
    "        observations = {}\n",
    "        for observing_agent in self.agents:\n",
    "            obs_segments = []\n",
    "            observing_agent_pos = self.agent_positions[observing_agent]\n",
    "            \n",
    "            for other_agent in self.agents:\n",
    "                if other_agent != observing_agent:\n",
    "                    obs_segments.append(self.agent_positions[other_agent] - observing_agent_pos)\n",
    "            obs_segments.append(self.button_pos- observing_agent_pos)\n",
    "            obs_segments.append(self.gate_pos -observing_agent_pos)\n",
    "            obs_segments.append(gate_status_info)\n",
    "            observations[observing_agent] = np.concatenate(obs_segments, dtype=np.float32)\n",
    "        return observations\n",
    "\n",
    "    '''\n",
    "    Functions for Sprite rendering and loading\n",
    "    '''    \n",
    "    def _create_missing_sprite(self, text, bg_color, border_color = (0,0,0)):  \n",
    "        error_sprite = pygame.Surface((self.cell_size, self.cell_size), pygame.SRCALPHA)\n",
    "        error_sprite.fill((0, 0, 0, 0))\n",
    "        center = (self.cell_size // 2, self.cell_size // 2)\n",
    "        radius = int(self.cell_size * 0.4)\n",
    "        pygame.draw.circle(error_sprite, bg_color, center, radius) \n",
    "        pygame.draw.circle(error_sprite, border_color, center, radius, 2)\n",
    "        \n",
    "        # Add text label\n",
    "        try:\n",
    "            font_size = int(self.cell_size * 0.22)\n",
    "            font = pygame.font.Font(None, font_size)   \n",
    "            text_color = (0, 0, 0) if sum(bg_color) > 300 else (255, 255, 255) \n",
    "            text_surface = font.render(text, True, text_color)\n",
    "            text_rect = text_surface.get_rect(center=center)\n",
    "            error_sprite.blit(text_surface, text_rect)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Error while writing text inside missing sprite {text}. A missing sprite without text label will be used for this simulation.\")\n",
    "            pass\n",
    "            \n",
    "        return error_sprite\n",
    "    \n",
    "    def _load_and_scale_sprite(self, filename, component_name):\n",
    "        path = os.path.join(SPRITES_DIR, filename)\n",
    "    \n",
    "        try:\n",
    "            image = pygame.image.load(path).convert_alpha() \n",
    "            scaled_size = int(self.cell_size )\n",
    "            return pygame.transform.scale(image, (scaled_size, scaled_size))\n",
    "            \n",
    "        except (FileNotFoundError, pygame.error) as e:\n",
    "            print(f\"WARNING! Sprite image {path} not found. Using default sprite for this simulation.\")\n",
    "    \n",
    "            text = component_name.upper() if component_name else \"ERROR\"\n",
    "            bg_color = (100, 100, 255) if \"AGENT\" in text else (128,128,128) # Blue agent, Gray fixed components\n",
    "            return self._create_missing_sprite(text, bg_color)\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            return\n",
    "\n",
    "        if self.window is None:\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            pygame.font.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "            \n",
    "            for agent_name in self.agents:\n",
    "               # self.agent_sprites[agent_name] = self._load_and_scale_sprite(f\"{agent_name}.png\", agent_name)\n",
    "               self.agent_sprites[agent_name] = self._load_and_scale_sprite(\".png\", agent_name)\n",
    "\n",
    "            for name, data in self.fixed_components.items():\n",
    "                self.component_sprites[name] = self._load_and_scale_sprite(data[\"file\"], name)\n",
    "\n",
    "                 \n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((220, 220, 220)) \n",
    "        pix_square_size = self.cell_size \n",
    "        sprite_offset = (pix_square_size - int(pix_square_size * 0.8)) // 2\n",
    "\n",
    "        # Render walls\n",
    "        for x in range(self.grid_size):\n",
    "            for y in range(self.grid_size):\n",
    "                if self.grid_map[x, y] == 1:\n",
    "                    pygame.draw.rect(\n",
    "                        canvas, \n",
    "                        (50, 50, 50),\n",
    "                        pygame.Rect(x * pix_square_size, y * pix_square_size, pix_square_size, pix_square_size)\n",
    "                    )\n",
    "\n",
    "        # Render fixed components and agents\n",
    "        for name, data in self.fixed_components.items():\n",
    "            if self.gate_open and name == \"gate_close\":\n",
    "                continue\n",
    "            pos = data[\"pos\"]\n",
    "            x_coord = pos[0] * pix_square_size + sprite_offset\n",
    "            y_coord = pos[1] * pix_square_size + sprite_offset\n",
    "            sprite = self.component_sprites[name]\n",
    "            canvas.blit(sprite, (x_coord, y_coord))\n",
    "\n",
    "        for agent in self.agents:\n",
    "            pos = self.agent_positions[agent]            \n",
    "            x_coord = pos[0] * pix_square_size + sprite_offset\n",
    "            y_coord = pos[1] * pix_square_size + sprite_offset\n",
    "            \n",
    "            sprite = self.agent_sprites[agent]\n",
    "            canvas.blit(sprite, (x_coord, y_coord))\n",
    "\n",
    "        # Render the grid\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas, 0, (0, pix_square_size * x), (self.window_size, pix_square_size * x), width=2\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas, 0, (pix_square_size * x, 0), (pix_square_size * x, self.window_size), width=2\n",
    "            )\n",
    "\n",
    "        # Display the render\n",
    "        self.window.blit(canvas, canvas.get_rect())\n",
    "        pygame.event.pump()\n",
    "        pygame.display.update()\n",
    "        self.clock.tick(4) # FPS\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5fd6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(config):\n",
    "    return ParallelPettingZooEnv(\n",
    "        MyGridWorld(render_mode=None)\n",
    "    )\n",
    "\n",
    "register_env(\"my_gridworld_pz\", env_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1cc4a4",
   "metadata": {},
   "source": [
    "## Configure PPO\n",
    "Set my custom environment\n",
    "\n",
    "Set policy\n",
    "\n",
    "Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ffbf61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:527: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=144499)\u001b[0m /home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(RolloutWorker pid=144499)\u001b[0m   from pkg_resources import resource_stream, resource_exists\n",
      "2025-12-24 00:55:30,435\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"my_gridworld_pz\")\n",
    "    .multi_agent(\n",
    "        policies={\"shared_policy\"},\n",
    "        policy_mapping_fn=lambda agent_id, *args, **kwargs: \"shared_policy\",\n",
    "    )\n",
    "    .env_runners(num_env_runners=1)  # tienilo a 1 per ora\n",
    "    .training(\n",
    "        lr=2e-4,\n",
    "        train_batch_size_per_learner=2000,\n",
    "        num_epochs=10,\n",
    "    )\n",
    "    .api_stack(\n",
    "        # IMPORTANTE: Disabilita tutto il nuovo stack per tornare alla stabilità\n",
    "        enable_rl_module_and_learner=False,\n",
    "        enable_env_runner_and_connector_v2=False\n",
    "    )\n",
    ")\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "ppo = config.build_algo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa056b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db9b4889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0:\n",
      " Rew:-68.00439510661514, len episode:100.0\n",
      "Iter:1:\n",
      " Rew:-61.61116105174354, len episode:100.0\n",
      "Iter:2:\n",
      " Rew:-47.73612641341209, len episode:98.73333333333333\n",
      "Iter:3:\n",
      " Rew:-31.461795179677566, len episode:96.89024390243902\n",
      "Iter:4:\n",
      " Rew:-2.7457494604087156, len episode:91.83\n",
      "Iter:5:\n",
      " Rew:34.34248115336146, len episode:85.92\n",
      "Iter:6:\n",
      " Rew:77.53622874900012, len episode:74.84\n",
      "Iter:7:\n",
      " Rew:133.52113628881415, len episode:59.77\n",
      "Iter:8:\n",
      " Rew:186.97783707816896, len episode:36.42\n",
      "Iter:9:\n",
      " Rew:192.21960709955027, len episode:25.68\n",
      "Iter:10:\n",
      " Rew:193.7629228417284, len episode:19.182692307692307\n",
      "Iter:11:\n",
      " Rew:194.13896282545414, len episode:17.102564102564102\n",
      "Iter:12:\n",
      " Rew:194.29482264207255, len episode:15.771653543307087\n",
      "Iter:13:\n",
      " Rew:194.8644891410996, len episode:14.3\n",
      "Iter:14:\n",
      " Rew:195.85094041751773, len episode:12.409937888198758\n",
      "Iter:15:\n",
      " Rew:195.76655453086508, len episode:12.320987654320987\n",
      "Iter:16:\n",
      " Rew:195.9562458231717, len episode:11.53448275862069\n",
      "Iter:17:\n",
      " Rew:196.16246064164034, len episode:11.044198895027625\n",
      "Iter:18:\n",
      " Rew:196.63495075789405, len episode:10.587301587301587\n",
      "Iter:19:\n",
      " Rew:196.82874058669142, len episode:10.0\n",
      "Iter:20:\n",
      " Rew:196.3506784065779, len episode:10.486910994764397\n",
      "Iter:21:\n",
      " Rew:196.90467728050106, len episode:9.852216748768473\n",
      "Iter:22:\n",
      " Rew:194.49749133050474, len episode:11.094444444444445\n",
      "Iter:23:\n",
      " Rew:196.5744692168522, len episode:10.06532663316583\n",
      "Iter:24:\n",
      " Rew:196.7596813249463, len episode:10.045226130653266\n",
      "Iter:25:\n",
      " Rew:197.05717204150272, len episode:9.66183574879227\n",
      "Iter:26:\n",
      " Rew:197.10037643193797, len episode:9.50952380952381\n",
      "Iter:27:\n",
      " Rew:197.0387658556918, len episode:9.75609756097561\n",
      "Iter:28:\n",
      " Rew:197.38324777485417, len episode:9.114155251141552\n",
      "Iter:29:\n",
      " Rew:197.16853019008886, len episode:9.583732057416269\n",
      "Iter:30:\n",
      " Rew:197.22121197997865, len episode:9.429245283018869\n",
      "Iter:31:\n",
      " Rew:196.59170663735352, len episode:10.204081632653061\n",
      "Iter:32:\n",
      " Rew:196.91858358737775, len episode:9.733009708737864\n",
      "Iter:33:\n",
      " Rew:197.08894645276774, len episode:9.55023923444976\n",
      "Iter:34:\n",
      " Rew:196.89970354413072, len episode:9.588516746411484\n",
      "Iter:35:\n",
      " Rew:196.9253060794317, len episode:9.78921568627451\n",
      "Iter:36:\n",
      " Rew:196.86537704001785, len episode:10.251282051282052\n",
      "Iter:37:\n",
      " Rew:197.18409009374386, len episode:9.507109004739336\n",
      "Iter:38:\n",
      " Rew:194.88590649326602, len episode:11.044198895027625\n",
      "Iter:39:\n",
      " Rew:196.77566448119674, len episode:10.183673469387756\n",
      "Iter:40:\n",
      " Rew:196.9914712544616, len episode:9.985\n",
      "Iter:41:\n",
      " Rew:197.36421078960072, len episode:9.45754716981132\n",
      "Iter:42:\n",
      " Rew:196.80528683343286, len episode:10.29896907216495\n",
      "Iter:43:\n",
      " Rew:197.23674529434115, len episode:9.547619047619047\n",
      "Iter:44:\n",
      " Rew:196.5731206998492, len episode:10.923497267759563\n",
      "Iter:45:\n",
      " Rew:196.7694521526646, len episode:10.842391304347826\n",
      "Iter:46:\n",
      " Rew:197.0969308674355, len episode:10.121212121212121\n",
      "Iter:47:\n",
      " Rew:196.8997303895271, len episode:10.256410256410257\n",
      "Iter:48:\n",
      " Rew:196.4172933186678, len episode:11.352272727272727\n",
      "Iter:49:\n",
      " Rew:196.72651016380686, len episode:10.395833333333334\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    result = ppo.train()\n",
    "    print(\n",
    "        f\"Iter:{i}:\\n Rew:{result['env_runners']['episode_return_mean']}, len episode:{result['env_runners']['episode_len_mean']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec15527",
   "metadata": {},
   "source": [
    "## Save the agents model in order to reuse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd783a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved into /home/terra/Desktop/unimore/distributed_project/src/policies/PPO/models/ck1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "model_dir = os.path.join(current_dir, \"models\")\n",
    "checkpoint_name = os.path.join(model_dir, \"ck1\")\n",
    "ppo.save(checkpoint_name)\n",
    "\n",
    "print(f\"Model saved into {checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3738be",
   "metadata": {},
   "source": [
    "## Load an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2029a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPO\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "model_dir = os.path.join(current_dir, \"models\")\n",
    "checkpoint_name = os.path.join(model_dir, \"ck1\")\n",
    "\n",
    "ppo = PPO.from_checkpoint(checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c4cf2",
   "metadata": {},
   "source": [
    "## Test the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28ae26d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Sprite image ./sprites/.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/button.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/gate_open.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/gate_close.png not found. Using default sprite for this simulation.\n",
      "Episodio terminato!\n",
      "Episodio terminato!\n",
      "Episodio terminato!\n"
     ]
    }
   ],
   "source": [
    "POLICY_ID = \"shared_policy\" \n",
    "\n",
    "env = MyGridWorld(grid_size=15, render_mode=\"human\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "i = 0\n",
    "while i<3:\n",
    "    actions = {}\n",
    "    for agent_id, agent_obs in obs.items():\n",
    "        actions[agent_id] = ppo.compute_single_action(\n",
    "            agent_obs, \n",
    "            policy_id=POLICY_ID,\n",
    "            explore=False\n",
    "        )\n",
    "\n",
    "    # Nota: result[\"evaluation\"]... è statico qui (è il valore dell'ultimo train), \n",
    "    # non cambia durante questo loop.\n",
    "    # print(\"TRAIN | episode_len_mean:\", result[\"evaluation\"][\"episode_len_mean\"])\n",
    "    \n",
    "    # 2. Passiamo il dizionario di azioni all'environment\n",
    "    obs, rewards, terminations, truncations, infos = env.step(actions)\n",
    "\n",
    "    # 3. Gestione fine episodio\n",
    "    if any(terminations.values()) or any(truncations.values()):\n",
    "        print(\"Episodio terminato!\")\n",
    "        obs, _ = env.reset()\n",
    "        i+=1\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MARL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
