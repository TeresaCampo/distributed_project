{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3cd819",
   "metadata": {},
   "source": [
    "# **My custom env - dense reward**\n",
    "\n",
    "**Environment classe pasted here in order to make it accessible to all the workers of Ray.**\n",
    "\n",
    "It is equivalent to /myenv_6_dense_reward.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ef575",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_examination = \"strictplay_2agents_densereward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b94dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project dir found: /home/terra/Desktop/unimore/distributed_project\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(os.getcwd()) \n",
    "pointed_dir = current_dir\n",
    "\n",
    "while True:\n",
    "    if pointed_dir.is_dir() and \"distributed_project\" == str(pointed_dir).split(\"/\")[-1]:\n",
    "        project_dir = pointed_dir\n",
    "        print(f\"Project dir found: {project_dir}\")\n",
    "        break\n",
    "    \n",
    "    if pointed_dir == pointed_dir.parent:\n",
    "        print(\"Error while looking for 'distributed_project', project dir\")\n",
    "        break\n",
    "        \n",
    "    pointed_dir = pointed_dir.parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a20e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from pettingzoo import ParallelEnv\n",
    "import pygame \n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "SPRITES_DIR = f\"{project_dir}/sprites\"\n",
    "\n",
    "\n",
    "class MyGridWorld(ParallelEnv):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"name\": \"custom_grid_v0\"}\n",
    "\n",
    "    def __init__(self, render_mode=None, n_agents = 2, grid_size=15):\n",
    "        if grid_size<8:\n",
    "            print(\"Error, need to insert a grid size greater or equal to 8\")\n",
    "        self.grid_size = grid_size\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        ######## Agents, fixed components, and forbidden positions\n",
    "        self.possible_agents = [f\"agent{i}\" for i in range(1, n_agents+1)]\n",
    "        self.agents = self.possible_agents[:]\n",
    "        self.gate_open = False\n",
    "\n",
    "        self.fixed_components = {\n",
    "            \"button1\":  {\"pos\": np.array([self.grid_size//2+2, 1+3+2]), \"file\": \"button.png\"},\n",
    "            \"button2\":  {\"pos\": np.array([self.grid_size//2+2, 1+1]), \"file\": \"button.png\"},\n",
    "\n",
    "            \"gate_open\":  {\"pos\": np.array([self.grid_size//2, 1+3]), \"file\": \"gate_open.png\"},\n",
    "            \"gate_close\":  {\"pos\": np.array([self.grid_size//2, 1+3]), \"file\": \"gate_close.png\"}   \n",
    "        }\n",
    "        self.button1_pos = self.fixed_components[\"button1\"][\"pos\"]\n",
    "        self.button2_pos = self.fixed_components[\"button2\"][\"pos\"]\n",
    "\n",
    "        self.gate_pos = self.fixed_components[\"gate_open\"][\"pos\"] \n",
    "        self.target_final_pos = self.gate_pos+[0, -1]\n",
    "\n",
    "        self.x_range = (1, self.grid_size-1-1)\n",
    "        self.y_range = (1+3+1, self.grid_size-1-1)\n",
    "        self.forbidden_position = {tuple(self.button1_pos)}    \n",
    "\n",
    "        self.max_cycles = 100\n",
    "        self.current_cycles = 0\n",
    "        ######## Pygame graphic configuration \n",
    "        self.window_size = 810\n",
    "        self.cell_size = self.window_size // self.grid_size\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "        # Walls\n",
    "        self.grid_map = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.grid_map[0, :] = 1\n",
    "        self.grid_map[:, 0] = 1\n",
    "        self.grid_map[-1, :] = 1\n",
    "        self.grid_map[:, -1] = 1\n",
    "        self.grid_map[ :, 1+3] = 1\n",
    "\n",
    "        # Sprites \n",
    "        self.agent_sprites = {}\n",
    "        self.component_sprites = {}\n",
    "\n",
    "        ######## Action space and observation space\n",
    "        # Five possible actions in each grid: stay(0), up(1), down(2), left(3), right(4)\n",
    "        self.action_spaces = {a: spaces.Discrete(5) for a in self.possible_agents}\n",
    "        OBSERVATION_DIM = 2*(len(self.agents)-1)+3*2+1\n",
    "        self.observation_spaces = {\n",
    "            a: spaces.Box(low=-(self.grid_size-1), high=self.grid_size-1, shape=(OBSERVATION_DIM,), dtype=np.float32) \n",
    "            for a in self.possible_agents\n",
    "        }\n",
    "        self.state_spaces = {a: None for a in self.possible_agents}\n",
    "\n",
    "    def state(self):\n",
    "        observations = self.gather_observations()\n",
    "        global_state = []\n",
    "        \n",
    "        for agent in self.possible_agents:\n",
    "            if agent in observations:\n",
    "                global_state.append(observations[agent])\n",
    "            else:\n",
    "                # Se l'agente Ã¨ morto/uscito, usa zeri\n",
    "                dim = self.observation_spaces[agent].shape[0]\n",
    "                global_state.append(np.zeros(dim, dtype=np.float32))\n",
    "                \n",
    "        return np.concatenate(global_state)\n",
    "\n",
    "    # Boilerplate PettingZoo\n",
    "    def observation_space(self, agent): return self.observation_spaces[agent]\n",
    "    def action_space(self, agent): return self.action_spaces[agent]\n",
    "\n",
    "    '''\n",
    "    Step in the environment\n",
    "    '''\n",
    "    def step(self, actions):\n",
    "        if not self.agents: return {}, {}, {}, {}, {}\n",
    "        self.current_cycles += 1\n",
    "        \n",
    "        rewards = {a: 0 for a in self.agents}\n",
    "\n",
    "        terminations = {a: False for a in self.agents}\n",
    "        truncations = {a: False for a in self.agents}\n",
    "        infos = {a: {\"is_success\":False} for a in self.agents}\n",
    "        \n",
    "        desired_positions = {}      \n",
    "        button_pressed = False\n",
    "        agents_desire_gate = []\n",
    "        for agent, action in actions.items():\n",
    "            current_pos = self.agent_positions[agent].copy()\n",
    "            target_pos = current_pos.copy()\n",
    "\n",
    "            if action == 1: target_pos[1] -= 1 \n",
    "            elif action == 2: target_pos[1] += 1\n",
    "            elif action == 3: target_pos[0] -= 1\n",
    "            elif action == 4: target_pos[0] += 1\n",
    "\n",
    "            # Monitor button, gate and walls\n",
    "            is_wall = self.grid_map[target_pos[0], target_pos[1]] == 1\n",
    "            is_gate = (target_pos == self.gate_pos).all()\n",
    "            is_button = (target_pos == self.button1_pos).all() or (target_pos == self.button2_pos).all()\n",
    "            \n",
    "            if is_button:\n",
    "                button_pressed = True\n",
    "            if is_gate:\n",
    "                agents_desire_gate.append((agent, current_pos))\n",
    "            \n",
    "            if is_wall and not is_gate:\n",
    "                desired_positions[agent] = current_pos \n",
    "            else:\n",
    "                desired_positions[agent] = target_pos\n",
    "                        \n",
    "        # If gate was open remove a wall, if gate was closed update the position of those who wanted to cross it\n",
    "        self.gate_open = button_pressed\n",
    "        if self.gate_open:\n",
    "            self.grid_map[self.gate_pos[0], self.gate_pos[1]] = 0\n",
    "        else:\n",
    "            self.grid_map[self.gate_pos[0], self.gate_pos[1]] = 1\n",
    "            for a in agents_desire_gate:\n",
    "                agent = a[0]\n",
    "                current_pos = a[1]\n",
    "                desired_positions[agent] = current_pos \n",
    "\n",
    "        # Check for conflicts (more than one agents have the same desired position)\n",
    "        final_positions = self.agent_positions.copy()\n",
    "        target_counts = defaultdict(list)         # Key: tuple(x, y) of desired positions, Value: list of agents desiring it\n",
    "        for agent, pos in desired_positions.items():\n",
    "            pos_tuple = tuple(pos)\n",
    "            target_counts[pos_tuple].append(agent)\n",
    "\n",
    "        # Solve eventual conflicts\n",
    "        for pos_tuple, agents_at_target in target_counts.items():      \n",
    "            # Case 1: no contended position\n",
    "            if len(agents_at_target) == 1:\n",
    "                agent = agents_at_target[0]\n",
    "                final_positions[agent] = desired_positions[agent]\n",
    "            \n",
    "            # Case 2: contended position\n",
    "            else:\n",
    "                one_agent_already_here_not_moving = None\n",
    "                for agent in agents_at_target:\n",
    "                    if tuple(self.agent_positions[agent]) == pos_tuple:\n",
    "                        one_agent_already_here_not_moving = agent\n",
    "                        break\n",
    "                \n",
    "                winning_agent = one_agent_already_here_not_moving if one_agent_already_here_not_moving else random.choice(agents_at_target)\n",
    "                final_positions[winning_agent] = desired_positions[winning_agent]\n",
    "                \n",
    "                agents_at_target.remove(winning_agent)\n",
    "                for losing_agent in agents_at_target[:]:\n",
    "                    final_positions[losing_agent] = self.agent_positions[losing_agent] \n",
    "        self.agent_positions = final_positions\n",
    "\n",
    "        # Negative reward if an agent is on the bottom area and is not pressing the button\n",
    "        agents_upper_area = 0\n",
    "        for a, pos in self.agent_positions.items():\n",
    "            dist_target = np.linalg.norm(pos - self.target_final_pos)\n",
    "            if pos[1]<4:                                # Agent on upper area\n",
    "                rewards[a] = +0.5\n",
    "                agents_upper_area+=1\n",
    "\n",
    "                if (pos == self.button2_pos).all():\n",
    "                    rewards[a] +=0.3\n",
    "            else:\n",
    "                rewards[a] -= (dist_target * 0.05)      # Agent on bottom area\n",
    "\n",
    "                if (pos == self.button1_pos).all():     # Agent on button\n",
    "                    rewards[a] += 0.3     \n",
    "       \n",
    "        if agents_upper_area == len(self.agents):\n",
    "            rewards = {a: +100 for a in self.agents}\n",
    "            terminations = {a: True for a in self.agents}\n",
    "            infos = {a: {\"is_success\":True} for a in self.agents}\n",
    "\n",
    "        if self.current_cycles >= self.max_cycles:\n",
    "            truncations= {a: True for a in self.agents}\n",
    "            \n",
    "        \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "            \n",
    "        final_obs = self.gather_observations()\n",
    "        self.agents = [a for a in self.agents if not terminations[a]]\n",
    "        return final_obs, rewards, terminations, truncations, infos\n",
    "   \n",
    "    '''\n",
    "    Determines initial condition of the simulation\n",
    "    '''\n",
    "\n",
    "    def generate_valid_position(self):\n",
    "        while True:\n",
    "            x = np.random.randint(self.x_range[0], self.x_range[1])\n",
    "            y = np.random.randint(self.y_range[0], self.y_range[1])\n",
    "            new_position = tuple((x, y))\n",
    "\n",
    "            if new_position not in self.forbidden_position:\n",
    "                return new_position\n",
    "            \n",
    "    def generate_set_initial_positions(self):\n",
    "        set_initial_positions = set()\n",
    "        while len(set_initial_positions)<len(self.possible_agents):\n",
    "            new_pos = self.generate_valid_position()\n",
    "            set_initial_positions.add(new_pos)\n",
    "        return set_initial_positions\n",
    "    \n",
    "    def generate_test_values(self, agent_num):\n",
    "        if agent_num==1:\n",
    "            return[7, 9]\n",
    "        else:\n",
    "            return [9,13]\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.agents = self.possible_agents[:]\n",
    "        set_initial_positions = list(self.generate_set_initial_positions())\n",
    "        self.current_cycles = 0\n",
    "\n",
    "        self.agent_positions = {}\n",
    "        for i, agent_id in enumerate(self.agents):\n",
    "            self.agent_positions[agent_id] = np.array(set_initial_positions[i])\n",
    "        \n",
    "        # To visualize the reset position if \"human\" mode on\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()         \n",
    "\n",
    "        return self.gather_observations(), {a: {} for a in self.agents}\n",
    "    \n",
    "    '''\n",
    "    Observation: [my_cur_pos, (other_cur) x number of other agents, button_pos, gate_pos, gate_open (1|0)]    '''\n",
    "    def gather_observations(self):\n",
    "        gate_status_info = np.array([int(self.gate_open)], dtype=np.float32)\n",
    "        observations = {}\n",
    "        for observing_agent in self.agents:\n",
    "            obs_segments = []\n",
    "            observing_agent_pos = self.agent_positions[observing_agent]\n",
    "            \n",
    "            for other_agent in self.agents:\n",
    "                if other_agent != observing_agent:\n",
    "                    obs_segments.append(self.agent_positions[other_agent] - observing_agent_pos)\n",
    "            obs_segments.append(self.button1_pos- observing_agent_pos)\n",
    "            obs_segments.append(self.button2_pos- observing_agent_pos)\n",
    "            obs_segments.append(self.gate_pos -observing_agent_pos)\n",
    "            obs_segments.append(gate_status_info)\n",
    "            observations[observing_agent] = np.concatenate(obs_segments, dtype=np.float32)\n",
    "        return observations\n",
    "\n",
    "    '''\n",
    "    Functions for Sprite rendering and loading\n",
    "    '''    \n",
    "    def _create_missing_sprite(self, text, bg_color, border_color = (0,0,0)):  \n",
    "        error_sprite = pygame.Surface((self.cell_size, self.cell_size), pygame.SRCALPHA)\n",
    "        error_sprite.fill((0, 0, 0, 0))\n",
    "        center = (self.cell_size // 2, self.cell_size // 2)\n",
    "        radius = int(self.cell_size * 0.4)\n",
    "        pygame.draw.circle(error_sprite, bg_color, center, radius) \n",
    "        pygame.draw.circle(error_sprite, border_color, center, radius, 2)\n",
    "        \n",
    "        # Add text label\n",
    "        try:\n",
    "            font_size = int(self.cell_size * 0.22)\n",
    "            font = pygame.font.Font(None, font_size)   \n",
    "            text_color = (0, 0, 0) if sum(bg_color) > 300 else (255, 255, 255) \n",
    "            text_surface = font.render(text, True, text_color)\n",
    "            text_rect = text_surface.get_rect(center=center)\n",
    "            error_sprite.blit(text_surface, text_rect)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Error while writing text inside missing sprite {text}. A missing sprite without text label will be used for this simulation.\")\n",
    "            pass\n",
    "            \n",
    "        return error_sprite\n",
    "    \n",
    "    def _load_and_scale_sprite(self, filename, component_name):\n",
    "        path = os.path.join(SPRITES_DIR, filename)\n",
    "    \n",
    "        try:\n",
    "            image = pygame.image.load(path).convert_alpha() \n",
    "            scaled_size = int(self.cell_size )\n",
    "            return pygame.transform.scale(image, (scaled_size, scaled_size))\n",
    "            \n",
    "        except (FileNotFoundError, pygame.error) as e:\n",
    "            print(f\"WARNING! Sprite image {path} not found. Using default sprite for this simulation.\")\n",
    "    \n",
    "            text = component_name.upper() if component_name else \"ERROR\"\n",
    "            bg_color = (100, 100, 255) if \"AGENT\" in text else (128,128,128) # Blue agent, Gray fixed components\n",
    "            return self._create_missing_sprite(text, bg_color)\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            return\n",
    "\n",
    "        if self.window is None:\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            pygame.font.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "            \n",
    "            for agent_name in self.agents:\n",
    "               # self.agent_sprites[agent_name] = self._load_and_scale_sprite(f\"{agent_name}.png\", agent_name)\n",
    "               self.agent_sprites[agent_name] = self._load_and_scale_sprite(\".png\", agent_name)\n",
    "\n",
    "            for name, data in self.fixed_components.items():\n",
    "                self.component_sprites[name] = self._load_and_scale_sprite(data[\"file\"], name)\n",
    "\n",
    "                 \n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((220, 220, 220)) \n",
    "        pix_square_size = self.cell_size \n",
    "        sprite_offset = (pix_square_size - int(pix_square_size * 0.8)) // 2\n",
    "\n",
    "        # Render walls\n",
    "        for x in range(self.grid_size):\n",
    "            for y in range(self.grid_size):\n",
    "                if self.grid_map[x, y] == 1:\n",
    "                    pygame.draw.rect(\n",
    "                        canvas, \n",
    "                        (50, 50, 50),\n",
    "                        pygame.Rect(x * pix_square_size, y * pix_square_size, pix_square_size, pix_square_size)\n",
    "                    )\n",
    "\n",
    "        # Render fixed components and agents\n",
    "        for name, data in self.fixed_components.items():\n",
    "            if self.gate_open and name == \"gate_close\":\n",
    "                continue\n",
    "            pos = data[\"pos\"]\n",
    "            x_coord = pos[0] * pix_square_size + sprite_offset\n",
    "            y_coord = pos[1] * pix_square_size + sprite_offset\n",
    "            sprite = self.component_sprites[name]\n",
    "            canvas.blit(sprite, (x_coord, y_coord))\n",
    "\n",
    "        for agent in self.agents:\n",
    "            pos = self.agent_positions[agent]            \n",
    "            x_coord = pos[0] * pix_square_size + sprite_offset\n",
    "            y_coord = pos[1] * pix_square_size + sprite_offset\n",
    "            \n",
    "            sprite = self.agent_sprites[agent]\n",
    "            canvas.blit(sprite, (x_coord, y_coord))\n",
    "\n",
    "        # Render the grid\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas, 0, (0, pix_square_size * x), (self.window_size, pix_square_size * x), width=2\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas, 0, (pix_square_size * x, 0), (pix_square_size * x, self.window_size), width=2\n",
    "            )\n",
    "\n",
    "        # Display the render\n",
    "        self.window.blit(canvas, canvas.get_rect())\n",
    "        pygame.event.pump()\n",
    "        pygame.display.update()\n",
    "        self.clock.tick(4) # FPS\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95118daf",
   "metadata": {},
   "source": [
    "**Wrap the envornment in a PettingZoo env (for compatibility with Ray) and register it on Ray lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5fd6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2025-12-27 11:27:04,444 E 763082 763082] (gcs_server) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(config):\n",
    "    return ParallelPettingZooEnv(\n",
    "        MyGridWorld(render_mode=None, n_agents=2)\n",
    "    )\n",
    "\n",
    "register_env(\"my_gridworld\", env_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1cc4a4",
   "metadata": {},
   "source": [
    "## **IPPO - strict play settings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0dc4f",
   "metadata": {},
   "source": [
    "Callback to register episode success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f520adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-12-27 11:27:05,316 E 763196 763196] (raylet) main.cc:1032: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(pid=763256)\u001b[0m [2025-12-27 11:27:06,244 E 763256 763386] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "[2025-12-27 11:27:06,511 E 762982 763249] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "class SuccessMetricCallback(DefaultCallbacks):\n",
    "    def on_episode_end(self, *, worker, base_env, policies, episode, **kwargs):\n",
    "        \n",
    "        is_success = False\n",
    "        one_agent_id = list(episode.get_agents())[-1]\n",
    "        last_info = episode.last_info_for(one_agent_id)\n",
    "        is_success = last_info[\"is_success\"]\n",
    "       \n",
    "        episode.custom_metrics[\"success_rate\"] = int(is_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de23d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"my_gridworld\")\n",
    "    .env_runners(num_env_runners=0)\n",
    "    .callbacks(callbacks_class=SuccessMetricCallback)\n",
    "    .multi_agent(\n",
    "        policies={\"shared_policy\"},\n",
    "        policy_mapping_fn=lambda agent_id, *args, **kwargs: \"shared_policy\",\n",
    "    )\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=False,\n",
    "        enable_env_runner_and_connector_v2=False\n",
    "    )\n",
    "    \n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "        evaluation_duration=10,\n",
    "        evaluation_duration_unit=\"episodes\",\n",
    "        evaluation_num_env_runners=1,\n",
    "        \n",
    "        evaluation_config={\n",
    "            \"explore\": True,\n",
    "        }\n",
    "    )\n",
    "    .training(\n",
    "    lr=1e-4,\n",
    "    train_batch_size_per_learner=4000,\n",
    "    num_epochs=5,\n",
    "    entropy_coeff=0.01,\n",
    "    kl_coeff=0.2,\n",
    "    kl_target=0.01\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656291d9",
   "metadata": {},
   "source": [
    "## **Wandb - One run of training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "#wandb.init(project=\"gridworld_looseplay_2agents\", name=\"densereward\")\n",
    "ppo = config.build_algo()\n",
    "num_total_episodes = 0\n",
    "for i in range(50):\n",
    "    result = ppo.train()\n",
    "    num_total_episodes += result['env_runners']['num_episodes']\n",
    "    \n",
    "    print(f\"ITERATION {i}, num episode {num_total_episodes}\".center(100,\"-\"))\n",
    "    train_rew = round(result['env_runners']['episode_return_mean'], 2)\n",
    "    train_steps_episode = round(result['env_runners']['episode_len_mean'], 2)\n",
    "    train_success_rate = round(result['env_runners']['custom_metrics'].get('success_rate_mean', 0), 2) * 100\n",
    "    print(f\"\"\"TRAINING\\nRew:{train_rew} \\nSteps per episode:{train_steps_episode} \\nSuccess rate:{train_success_rate}%\\n\"\"\")\n",
    "\n",
    "    if 'evaluation' in result:\n",
    "        testing_rew = round(result['evaluation']['env_runners']['episode_return_mean'], 2)\n",
    "        testing_steps_episode = round(result['evaluation']['env_runners']['episode_len_mean'], 2)\n",
    "        testing_success_rate = round(result['evaluation']['env_runners']['custom_metrics'].get('success_rate_mean', 0), 2) * 100\n",
    "        print(f\"\"\"TESTING\\nRew:{testing_rew} \\nSteps per episode:{testing_steps_episode} \\nSuccess rate:{testing_success_rate}%\\n\\n\"\"\")\n",
    "\n",
    "    log_data = {\n",
    "        \"Episodes\": num_total_episodes,\n",
    "\n",
    "        \"Training_steps_per_episode\": train_steps_episode,\n",
    "        \"Training_success_rate_per_episode\": train_success_rate,\n",
    "        \"Training_reward_per_episode\": train_rew,\n",
    "\n",
    "        \"Testing_steps_per_episode\": testing_steps_episode,\n",
    "        \"Testing_success_rate_per_episode\": testing_success_rate,\n",
    "        \"Testing_reward_per_episode\": testing_rew\n",
    "    }\n",
    "    #wandb.log(log_data)\n",
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ad7bb",
   "metadata": {},
   "source": [
    "## **Wandb, 3 runs of training to generate esteme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "RUN NUMBER 1/3\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:527: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "[2025-12-27 11:27:20,088 E 762982 762982] core_worker.cc:2223: Actor with class name: 'RolloutWorker' and ID: 'f6d02107a53f0541d9f1e87401000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(RolloutWorker pid=763256)\u001b[0m /home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(RolloutWorker pid=763256)\u001b[0m   from pkg_resources import resource_stream, resource_exists\n",
      "2025-12-27 11:27:23,161\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m299011\u001b[0m (\u001b[33m299011-unimore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/terra/Desktop/unimore/distributed_project/src/policies/PPO/wandb/run-20251227_112724-9kq2ahii</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/9kq2ahii' target=\"_blank\">run_1</a></strong> to <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/9kq2ahii' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/9kq2ahii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 11:27:35,360\tWARNING sgd.py:55 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ITERATION 0, num episode 40-------------------------------------\n",
      "TRAINING\n",
      "Rew:-71.26 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-57.05 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 1, num episode 80-------------------------------------\n",
      "TRAINING\n",
      "Rew:-60.48 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-39.74 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 2, num episode 120------------------------------------\n",
      "TRAINING\n",
      "Rew:-47.8 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-24.0 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 3, num episode 160------------------------------------\n",
      "TRAINING\n",
      "Rew:-33.55 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-26.01 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 4, num episode 200------------------------------------\n",
      "TRAINING\n",
      "Rew:-23.23 \n",
      "Steps per episode:99.91 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:2.67 \n",
      "Steps per episode:98.89 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 5, num episode 240------------------------------------\n",
      "TRAINING\n",
      "Rew:-13.54 \n",
      "Steps per episode:99.23 \n",
      "Success rate:4.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-25.98 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 6, num episode 280------------------------------------\n",
      "TRAINING\n",
      "Rew:-13.97 \n",
      "Steps per episode:99.32 \n",
      "Success rate:3.0%\n",
      "\n",
      "TESTING\n",
      "Rew:9.64 \n",
      "Steps per episode:98.78 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 7, num episode 321------------------------------------\n",
      "TRAINING\n",
      "Rew:-8.33 \n",
      "Steps per episode:99.1 \n",
      "Success rate:5.0%\n",
      "\n",
      "TESTING\n",
      "Rew:16.65 \n",
      "Steps per episode:98.22 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 8, num episode 365------------------------------------\n",
      "TRAINING\n",
      "Rew:4.94 \n",
      "Steps per episode:95.66 \n",
      "Success rate:11.0%\n",
      "\n",
      "TESTING\n",
      "Rew:106.31 \n",
      "Steps per episode:77.44 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 9, num episode 410------------------------------------\n",
      "TRAINING\n",
      "Rew:26.26 \n",
      "Steps per episode:91.11 \n",
      "Success rate:21.0%\n",
      "\n",
      "TESTING\n",
      "Rew:147.36 \n",
      "Steps per episode:69.78 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 10, num episode 458------------------------------------\n",
      "TRAINING\n",
      "Rew:63.27 \n",
      "Steps per episode:86.67 \n",
      "Success rate:37.0%\n",
      "\n",
      "TESTING\n",
      "Rew:35.45 \n",
      "Steps per episode:89.67 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 11, num episode 510------------------------------------\n",
      "TRAINING\n",
      "Rew:101.02 \n",
      "Steps per episode:80.3 \n",
      "Success rate:54.0%\n",
      "\n",
      "TESTING\n",
      "Rew:85.37 \n",
      "Steps per episode:83.67 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 12, num episode 563------------------------------------\n",
      "TRAINING\n",
      "Rew:124.57 \n",
      "Steps per episode:76.87 \n",
      "Success rate:64.0%\n",
      "\n",
      "TESTING\n",
      "Rew:81.79 \n",
      "Steps per episode:88.33 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 13, num episode 625------------------------------------\n",
      "TRAINING\n",
      "Rew:145.3 \n",
      "Steps per episode:68.8 \n",
      "Success rate:74.0%\n",
      "\n",
      "TESTING\n",
      "Rew:172.19 \n",
      "Steps per episode:55.56 \n",
      "Success rate:89.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 14, num episode 689------------------------------------\n",
      "TRAINING\n",
      "Rew:166.94 \n",
      "Steps per episode:63.64 \n",
      "Success rate:85.0%\n",
      "\n",
      "TESTING\n",
      "Rew:178.28 \n",
      "Steps per episode:53.78 \n",
      "Success rate:89.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 15, num episode 759------------------------------------\n",
      "TRAINING\n",
      "Rew:177.53 \n",
      "Steps per episode:57.82 \n",
      "Success rate:90.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.0 \n",
      "Steps per episode:44.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 16, num episode 839------------------------------------\n",
      "TRAINING\n",
      "Rew:190.35 \n",
      "Steps per episode:51.71 \n",
      "Success rate:96.0%\n",
      "\n",
      "TESTING\n",
      "Rew:154.62 \n",
      "Steps per episode:49.44 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 17, num episode 927------------------------------------\n",
      "TRAINING\n",
      "Rew:191.52 \n",
      "Steps per episode:46.42 \n",
      "Success rate:96.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.11 \n",
      "Steps per episode:43.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 18, num episode 1033-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.29 \n",
      "Steps per episode:37.52 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.78 \n",
      "Steps per episode:40.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 19, num episode 1157-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.42 \n",
      "Steps per episode:32.41 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.3 \n",
      "Steps per episode:28.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 20, num episode 1292-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.83 \n",
      "Steps per episode:29.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.0 \n",
      "Steps per episode:25.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 21, num episode 1442-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.33 \n",
      "Steps per episode:26.69 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.34 \n",
      "Steps per episode:22.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 22, num episode 1609-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.14 \n",
      "Steps per episode:23.96 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.72 \n",
      "Steps per episode:28.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 23, num episode 1782-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.1 \n",
      "Steps per episode:23.08 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.1 \n",
      "Steps per episode:26.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 24, num episode 1959-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.67 \n",
      "Steps per episode:22.53 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.66 \n",
      "Steps per episode:20.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 25, num episode 2144-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.33 \n",
      "Steps per episode:21.69 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.56 \n",
      "Steps per episode:22.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 26, num episode 2336-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.27 \n",
      "Steps per episode:20.84 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.64 \n",
      "Steps per episode:19.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 27, num episode 2518-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.37 \n",
      "Steps per episode:22.04 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.93 \n",
      "Steps per episode:19.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 28, num episode 2703-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.2 \n",
      "Steps per episode:21.61 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.19 \n",
      "Steps per episode:19.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 29, num episode 2906-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.65 \n",
      "Steps per episode:19.65 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.41 \n",
      "Steps per episode:19.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 30, num episode 3099-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.84 \n",
      "Steps per episode:20.7 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.01 \n",
      "Steps per episode:17.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 31, num episode 3303-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.66 \n",
      "Steps per episode:19.7 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.16 \n",
      "Steps per episode:16.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 32, num episode 3509-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.47 \n",
      "Steps per episode:19.41 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.38 \n",
      "Steps per episode:16.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 33, num episode 3733-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.27 \n",
      "Steps per episode:17.86 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.44 \n",
      "Steps per episode:19.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 34, num episode 3938-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.12 \n",
      "Steps per episode:19.47 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.08 \n",
      "Steps per episode:16.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 35, num episode 4154-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.45 \n",
      "Steps per episode:18.45 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.04 \n",
      "Steps per episode:17.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 36, num episode 4378-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.08 \n",
      "Steps per episode:17.91 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.49 \n",
      "Steps per episode:17.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 37, num episode 4589-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.66 \n",
      "Steps per episode:18.95 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.19 \n",
      "Steps per episode:16.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 38, num episode 4808-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.92 \n",
      "Steps per episode:18.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.07 \n",
      "Steps per episode:18.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 39, num episode 5042-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.5 \n",
      "Steps per episode:17.05 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.02 \n",
      "Steps per episode:13.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 40, num episode 5277-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.76 \n",
      "Steps per episode:17.03 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.28 \n",
      "Steps per episode:18.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 41, num episode 5507-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.5 \n",
      "Steps per episode:17.41 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.63 \n",
      "Steps per episode:17.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 42, num episode 5721-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.35 \n",
      "Steps per episode:18.7 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.26 \n",
      "Steps per episode:16.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 43, num episode 5941-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.0 \n",
      "Steps per episode:18.17 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.49 \n",
      "Steps per episode:17.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 44, num episode 6165-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.58 \n",
      "Steps per episode:17.8 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.21 \n",
      "Steps per episode:18.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 45, num episode 6390-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.04 \n",
      "Steps per episode:17.84 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.17 \n",
      "Steps per episode:15.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 46, num episode 6596-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.54 \n",
      "Steps per episode:19.43 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.34 \n",
      "Steps per episode:20.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 47, num episode 6788-----------------------------------\n",
      "TRAINING\n",
      "Rew:201.17 \n",
      "Steps per episode:20.81 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.25 \n",
      "Steps per episode:16.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 48, num episode 7012-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.97 \n",
      "Steps per episode:17.86 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.8 \n",
      "Steps per episode:17.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 49, num episode 7247-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.55 \n",
      "Steps per episode:17.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.4 \n",
      "Steps per episode:15.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "Model saved into /home/terra/Desktop/unimore/distributed_project/src/policies/PPO/models/loosplay_2agents_densereward_run_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52019c94358452e92dbce156ac0df03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>7247</td></tr><tr><td>Testing_reward_per_episode</td><td>199.4</td></tr><tr><td>Testing_steps_per_episode</td><td>15.44</td></tr><tr><td>Testing_success_rate_per_episode</td><td>100.0</td></tr><tr><td>Training_reward_per_episode</td><td>199.55</td></tr><tr><td>Training_steps_per_episode</td><td>17.0</td></tr><tr><td>Training_success_rate_per_episode</td><td>100.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1</strong> at: <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/9kq2ahii' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/9kq2ahii</a><br/> View project at: <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251227_112724-9kq2ahii/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "RUN NUMBER 2/3\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:527: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=763261)\u001b[0m /home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(RolloutWorker pid=763261)\u001b[0m   from pkg_resources import resource_stream, resource_exists\n",
      "2025-12-27 11:34:56,498\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/terra/Desktop/unimore/distributed_project/src/policies/PPO/wandb/run-20251227_113456-s0k9vp3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/s0k9vp3n' target=\"_blank\">run_2</a></strong> to <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/s0k9vp3n' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/s0k9vp3n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ITERATION 0, num episode 40-------------------------------------\n",
      "TRAINING\n",
      "Rew:-70.63 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-56.41 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 1, num episode 80-------------------------------------\n",
      "TRAINING\n",
      "Rew:-63.68 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-36.67 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 2, num episode 120------------------------------------\n",
      "TRAINING\n",
      "Rew:-52.61 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-24.78 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 3, num episode 160------------------------------------\n",
      "TRAINING\n",
      "Rew:-35.78 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-0.49 \n",
      "Steps per episode:98.11 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 4, num episode 200------------------------------------\n",
      "TRAINING\n",
      "Rew:-23.13 \n",
      "Steps per episode:99.84 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-26.62 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 5, num episode 241------------------------------------\n",
      "TRAINING\n",
      "Rew:-3.79 \n",
      "Steps per episode:98.1 \n",
      "Success rate:8.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-22.03 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 6, num episode 282------------------------------------\n",
      "TRAINING\n",
      "Rew:2.52 \n",
      "Steps per episode:97.3 \n",
      "Success rate:11.0%\n",
      "\n",
      "TESTING\n",
      "Rew:31.17 \n",
      "Steps per episode:94.67 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 7, num episode 325------------------------------------\n",
      "TRAINING\n",
      "Rew:8.19 \n",
      "Steps per episode:95.95 \n",
      "Success rate:14.000000000000002%\n",
      "\n",
      "TESTING\n",
      "Rew:74.16 \n",
      "Steps per episode:87.22 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 8, num episode 366------------------------------------\n",
      "TRAINING\n",
      "Rew:16.06 \n",
      "Steps per episode:95.06 \n",
      "Success rate:17.0%\n",
      "\n",
      "TESTING\n",
      "Rew:51.86 \n",
      "Steps per episode:92.22 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 9, num episode 413------------------------------------\n",
      "TRAINING\n",
      "Rew:45.03 \n",
      "Steps per episode:91.31 \n",
      "Success rate:28.999999999999996%\n",
      "\n",
      "TESTING\n",
      "Rew:74.87 \n",
      "Steps per episode:80.89 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 10, num episode 461------------------------------------\n",
      "TRAINING\n",
      "Rew:77.22 \n",
      "Steps per episode:85.58 \n",
      "Success rate:44.0%\n",
      "\n",
      "TESTING\n",
      "Rew:106.6 \n",
      "Steps per episode:73.11 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 11, num episode 510------------------------------------\n",
      "TRAINING\n",
      "Rew:95.75 \n",
      "Steps per episode:82.37 \n",
      "Success rate:53.0%\n",
      "\n",
      "TESTING\n",
      "Rew:127.24 \n",
      "Steps per episode:69.22 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 12, num episode 575------------------------------------\n",
      "TRAINING\n",
      "Rew:146.34 \n",
      "Steps per episode:67.52 \n",
      "Success rate:76.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.38 \n",
      "Steps per episode:54.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 13, num episode 642------------------------------------\n",
      "TRAINING\n",
      "Rew:172.53 \n",
      "Steps per episode:59.47 \n",
      "Success rate:88.0%\n",
      "\n",
      "TESTING\n",
      "Rew:196.55 \n",
      "Steps per episode:59.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 14, num episode 721------------------------------------\n",
      "TRAINING\n",
      "Rew:182.34 \n",
      "Steps per episode:54.01 \n",
      "Success rate:92.0%\n",
      "\n",
      "TESTING\n",
      "Rew:196.63 \n",
      "Steps per episode:42.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 15, num episode 810------------------------------------\n",
      "TRAINING\n",
      "Rew:193.49 \n",
      "Steps per episode:46.03 \n",
      "Success rate:98.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.23 \n",
      "Steps per episode:38.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 16, num episode 914------------------------------------\n",
      "TRAINING\n",
      "Rew:198.66 \n",
      "Steps per episode:38.31 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.13 \n",
      "Steps per episode:38.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 17, num episode 1037-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.48 \n",
      "Steps per episode:32.34 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.85 \n",
      "Steps per episode:26.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 18, num episode 1165-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.08 \n",
      "Steps per episode:31.32 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.34 \n",
      "Steps per episode:30.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 19, num episode 1293-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.1 \n",
      "Steps per episode:31.41 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.91 \n",
      "Steps per episode:25.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 20, num episode 1450-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.21 \n",
      "Steps per episode:25.45 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.32 \n",
      "Steps per episode:28.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 21, num episode 1623-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.62 \n",
      "Steps per episode:23.14 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:197.9 \n",
      "Steps per episode:22.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 22, num episode 1799-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.72 \n",
      "Steps per episode:22.68 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.82 \n",
      "Steps per episode:21.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 23, num episode 1992-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.76 \n",
      "Steps per episode:20.69 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.2 \n",
      "Steps per episode:21.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 24, num episode 2191-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.74 \n",
      "Steps per episode:20.15 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.05 \n",
      "Steps per episode:19.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 25, num episode 2399-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.21 \n",
      "Steps per episode:19.21 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.27 \n",
      "Steps per episode:22.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 26, num episode 2607-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.29 \n",
      "Steps per episode:19.3 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.44 \n",
      "Steps per episode:19.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 27, num episode 2806-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.75 \n",
      "Steps per episode:20.05 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.74 \n",
      "Steps per episode:17.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 28, num episode 3020-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.2 \n",
      "Steps per episode:18.75 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.32 \n",
      "Steps per episode:19.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 29, num episode 3249-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.9 \n",
      "Steps per episode:17.49 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.33 \n",
      "Steps per episode:19.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 30, num episode 3462-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.41 \n",
      "Steps per episode:18.77 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.86 \n",
      "Steps per episode:17.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 31, num episode 3683-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.33 \n",
      "Steps per episode:18.09 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.73 \n",
      "Steps per episode:17.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 32, num episode 3897-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.56 \n",
      "Steps per episode:18.62 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.0 \n",
      "Steps per episode:16.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 33, num episode 4115-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.16 \n",
      "Steps per episode:18.4 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.18 \n",
      "Steps per episode:16.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 34, num episode 4346-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.29 \n",
      "Steps per episode:17.36 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.52 \n",
      "Steps per episode:17.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 35, num episode 4574-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.82 \n",
      "Steps per episode:17.52 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.92 \n",
      "Steps per episode:18.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 36, num episode 4796-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.1 \n",
      "Steps per episode:18.04 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.67 \n",
      "Steps per episode:18.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 37, num episode 5026-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.4 \n",
      "Steps per episode:17.36 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:197.9 \n",
      "Steps per episode:17.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 38, num episode 5241-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.72 \n",
      "Steps per episode:18.53 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.41 \n",
      "Steps per episode:16.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 39, num episode 5458-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.67 \n",
      "Steps per episode:18.51 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.23 \n",
      "Steps per episode:20.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 40, num episode 5663-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.6 \n",
      "Steps per episode:19.5 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.32 \n",
      "Steps per episode:17.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 41, num episode 5892-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.08 \n",
      "Steps per episode:17.42 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.55 \n",
      "Steps per episode:21.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 42, num episode 6116-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.14 \n",
      "Steps per episode:17.87 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.81 \n",
      "Steps per episode:17.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 43, num episode 6342-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.77 \n",
      "Steps per episode:17.77 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.73 \n",
      "Steps per episode:17.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 44, num episode 6561-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.55 \n",
      "Steps per episode:18.25 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.21 \n",
      "Steps per episode:16.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 45, num episode 6769-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.84 \n",
      "Steps per episode:19.21 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.01 \n",
      "Steps per episode:18.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 46, num episode 7002-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.52 \n",
      "Steps per episode:17.2 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.97 \n",
      "Steps per episode:16.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 47, num episode 7233-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.71 \n",
      "Steps per episode:17.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.86 \n",
      "Steps per episode:17.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 48, num episode 7464-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.59 \n",
      "Steps per episode:17.26 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.74 \n",
      "Steps per episode:23.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 49, num episode 7675-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.4 \n",
      "Steps per episode:18.95 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.94 \n",
      "Steps per episode:17.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "Model saved into /home/terra/Desktop/unimore/distributed_project/src/policies/PPO/models/loosplay_2agents_densereward_run_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59f1326f10d42d38805e10adc7ed3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>7675</td></tr><tr><td>Testing_reward_per_episode</td><td>199.94</td></tr><tr><td>Testing_steps_per_episode</td><td>17.89</td></tr><tr><td>Testing_success_rate_per_episode</td><td>100.0</td></tr><tr><td>Training_reward_per_episode</td><td>200.4</td></tr><tr><td>Training_steps_per_episode</td><td>18.95</td></tr><tr><td>Training_success_rate_per_episode</td><td>100.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2</strong> at: <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/s0k9vp3n' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/s0k9vp3n</a><br/> View project at: <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251227_113456-s0k9vp3n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "RUN NUMBER 3/3\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:527: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=763251)\u001b[0m /home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(RolloutWorker pid=763251)\u001b[0m   from pkg_resources import resource_stream, resource_exists\n",
      "2025-12-27 11:43:00,264\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/terra/Desktop/unimore/distributed_project/src/policies/PPO/wandb/run-20251227_114300-nfu3tt2y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/nfu3tt2y' target=\"_blank\">run_3</a></strong> to <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/nfu3tt2y' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/nfu3tt2y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ITERATION 0, num episode 40-------------------------------------\n",
      "TRAINING\n",
      "Rew:-69.59 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-55.56 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 1, num episode 80-------------------------------------\n",
      "TRAINING\n",
      "Rew:-59.28 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-30.93 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 2, num episode 120------------------------------------\n",
      "TRAINING\n",
      "Rew:-44.91 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-1.67 \n",
      "Steps per episode:95.11 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 3, num episode 160------------------------------------\n",
      "TRAINING\n",
      "Rew:-29.0 \n",
      "Steps per episode:100.0 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-20.4 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 4, num episode 200------------------------------------\n",
      "TRAINING\n",
      "Rew:-23.22 \n",
      "Steps per episode:100.0 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-4.82 \n",
      "Steps per episode:99.44 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 5, num episode 240------------------------------------\n",
      "TRAINING\n",
      "Rew:-21.32 \n",
      "Steps per episode:99.67 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-11.99 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 6, num episode 281------------------------------------\n",
      "TRAINING\n",
      "Rew:-12.03 \n",
      "Steps per episode:98.36 \n",
      "Success rate:4.0%\n",
      "\n",
      "TESTING\n",
      "Rew:12.52 \n",
      "Steps per episode:97.11 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 7, num episode 325------------------------------------\n",
      "TRAINING\n",
      "Rew:18.9 \n",
      "Steps per episode:94.54 \n",
      "Success rate:16.0%\n",
      "\n",
      "TESTING\n",
      "Rew:43.79 \n",
      "Steps per episode:88.67 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 8, num episode 368------------------------------------\n",
      "TRAINING\n",
      "Rew:35.0 \n",
      "Steps per episode:92.57 \n",
      "Success rate:24.0%\n",
      "\n",
      "TESTING\n",
      "Rew:50.69 \n",
      "Steps per episode:83.89 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 9, num episode 419------------------------------------\n",
      "TRAINING\n",
      "Rew:71.06 \n",
      "Steps per episode:86.16 \n",
      "Success rate:41.0%\n",
      "\n",
      "TESTING\n",
      "Rew:110.96 \n",
      "Steps per episode:81.0 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 10, num episode 475------------------------------------\n",
      "TRAINING\n",
      "Rew:125.71 \n",
      "Steps per episode:75.45 \n",
      "Success rate:66.0%\n",
      "\n",
      "TESTING\n",
      "Rew:175.01 \n",
      "Steps per episode:63.56 \n",
      "Success rate:89.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 11, num episode 533------------------------------------\n",
      "TRAINING\n",
      "Rew:146.85 \n",
      "Steps per episode:71.74 \n",
      "Success rate:76.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.65 \n",
      "Steps per episode:47.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 12, num episode 607------------------------------------\n",
      "TRAINING\n",
      "Rew:173.58 \n",
      "Steps per episode:57.38 \n",
      "Success rate:88.0%\n",
      "\n",
      "TESTING\n",
      "Rew:204.73 \n",
      "Steps per episode:49.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 13, num episode 694------------------------------------\n",
      "TRAINING\n",
      "Rew:192.48 \n",
      "Steps per episode:46.29 \n",
      "Success rate:97.0%\n",
      "\n",
      "TESTING\n",
      "Rew:197.36 \n",
      "Steps per episode:43.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 14, num episode 792------------------------------------\n",
      "TRAINING\n",
      "Rew:198.73 \n",
      "Steps per episode:40.9 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.32 \n",
      "Steps per episode:42.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 15, num episode 898------------------------------------\n",
      "TRAINING\n",
      "Rew:199.89 \n",
      "Steps per episode:37.92 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.13 \n",
      "Steps per episode:25.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 16, num episode 1038-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.31 \n",
      "Steps per episode:28.64 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.94 \n",
      "Steps per episode:25.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 17, num episode 1180-----------------------------------\n",
      "TRAINING\n",
      "Rew:201.02 \n",
      "Steps per episode:28.12 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.32 \n",
      "Steps per episode:23.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 18, num episode 1338-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.72 \n",
      "Steps per episode:25.35 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.56 \n",
      "Steps per episode:25.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 19, num episode 1498-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.93 \n",
      "Steps per episode:25.02 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.26 \n",
      "Steps per episode:21.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 20, num episode 1679-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.89 \n",
      "Steps per episode:21.93 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.75 \n",
      "Steps per episode:25.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 21, num episode 1867-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.68 \n",
      "Steps per episode:21.38 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.72 \n",
      "Steps per episode:17.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 22, num episode 2062-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.1 \n",
      "Steps per episode:20.52 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.48 \n",
      "Steps per episode:20.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 23, num episode 2255-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.89 \n",
      "Steps per episode:20.65 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.23 \n",
      "Steps per episode:21.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 24, num episode 2465-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.88 \n",
      "Steps per episode:19.08 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.48 \n",
      "Steps per episode:18.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 25, num episode 2662-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.81 \n",
      "Steps per episode:20.35 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.64 \n",
      "Steps per episode:19.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 26, num episode 2870-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.78 \n",
      "Steps per episode:19.27 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.88 \n",
      "Steps per episode:18.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 27, num episode 3095-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.21 \n",
      "Steps per episode:17.77 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.45 \n",
      "Steps per episode:16.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 28, num episode 3331-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.25 \n",
      "Steps per episode:16.91 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.09 \n",
      "Steps per episode:15.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 29, num episode 3566-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.9 \n",
      "Steps per episode:17.03 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.81 \n",
      "Steps per episode:16.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 30, num episode 3785-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.64 \n",
      "Steps per episode:18.31 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.13 \n",
      "Steps per episode:19.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 31, num episode 4010-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.76 \n",
      "Steps per episode:17.73 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.36 \n",
      "Steps per episode:13.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 32, num episode 4240-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.64 \n",
      "Steps per episode:17.39 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.33 \n",
      "Steps per episode:13.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 33, num episode 4473-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.66 \n",
      "Steps per episode:17.19 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.29 \n",
      "Steps per episode:18.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 34, num episode 4712-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.32 \n",
      "Steps per episode:16.76 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.26 \n",
      "Steps per episode:19.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 35, num episode 4946-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.53 \n",
      "Steps per episode:17.06 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.53 \n",
      "Steps per episode:16.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 36, num episode 5176-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.82 \n",
      "Steps per episode:17.37 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.83 \n",
      "Steps per episode:17.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 37, num episode 5414-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.8 \n",
      "Steps per episode:16.85 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.24 \n",
      "Steps per episode:17.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 38, num episode 5652-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.74 \n",
      "Steps per episode:16.8 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:204.19 \n",
      "Steps per episode:28.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 39, num episode 5831-----------------------------------\n",
      "TRAINING\n",
      "Rew:201.98 \n",
      "Steps per episode:22.3 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.84 \n",
      "Steps per episode:20.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 40, num episode 6035-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.61 \n",
      "Steps per episode:19.68 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.97 \n",
      "Steps per episode:19.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 41, num episode 6241-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.61 \n",
      "Steps per episode:19.36 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.01 \n",
      "Steps per episode:18.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 42, num episode 6441-----------------------------------\n",
      "TRAINING\n",
      "Rew:200.55 \n",
      "Steps per episode:20.02 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.48 \n",
      "Steps per episode:16.33 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 43, num episode 6673-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.74 \n",
      "Steps per episode:17.27 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.24 \n",
      "Steps per episode:17.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 44, num episode 6918-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.53 \n",
      "Steps per episode:16.31 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.98 \n",
      "Steps per episode:13.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 45, num episode 7156-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.61 \n",
      "Steps per episode:16.76 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.85 \n",
      "Steps per episode:16.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 46, num episode 7381-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.75 \n",
      "Steps per episode:17.85 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.19 \n",
      "Steps per episode:18.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 47, num episode 7607-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.66 \n",
      "Steps per episode:17.69 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.52 \n",
      "Steps per episode:16.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 48, num episode 7845-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.7 \n",
      "Steps per episode:16.82 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.59 \n",
      "Steps per episode:16.56 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 49, num episode 8079-----------------------------------\n",
      "TRAINING\n",
      "Rew:199.51 \n",
      "Steps per episode:17.09 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.02 \n",
      "Steps per episode:17.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "Model saved into /home/terra/Desktop/unimore/distributed_project/src/policies/PPO/models/loosplay_2agents_densereward_run_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3556845dbf407092ce313f11892dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>8079</td></tr><tr><td>Testing_reward_per_episode</td><td>200.02</td></tr><tr><td>Testing_steps_per_episode</td><td>17.44</td></tr><tr><td>Testing_success_rate_per_episode</td><td>100.0</td></tr><tr><td>Training_reward_per_episode</td><td>199.51</td></tr><tr><td>Training_steps_per_episode</td><td>17.09</td></tr><tr><td>Training_success_rate_per_episode</td><td>100.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3</strong> at: <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/nfu3tt2y' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents/runs/nfu3tt2y</a><br/> View project at: <a href='https://wandb.ai/299011-unimore/gridworld_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_looseplay_2agents</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251227_114300-nfu3tt2y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "group_name = \"dense\"\n",
    "\n",
    "for run_idx in range(1,4):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"RUN NUMBER {run_idx}/3\")\n",
    "    print(f\"{'='*40}\\n\")\n",
    "\n",
    "    ppo = config.build_algo()\n",
    "    wandb.init(\n",
    "        project=\"gridworld_strictplay_2agents\",\n",
    "        group=group_name,           \n",
    "        name=f\"run_{run_idx}\",    \n",
    "        reinit=True \n",
    "    )\n",
    "    file_name = f\"{under_examination}_run_{run_idx}\"\n",
    "    \n",
    "    num_total_episodes = 0\n",
    "    for i in range(50):\n",
    "        result = ppo.train()\n",
    "        num_total_episodes += result['env_runners']['num_episodes']\n",
    "        \n",
    "        print(f\"ITERATION {i}, num episode {num_total_episodes}\".center(100,\"-\"))\n",
    "        train_rew = round(result['env_runners']['episode_return_mean'], 2)\n",
    "        train_steps_episode = round(result['env_runners']['episode_len_mean'], 2)\n",
    "        train_success_rate = round(result['env_runners']['custom_metrics'].get('success_rate_mean', 0), 2) * 100\n",
    "        print(f\"\"\"TRAINING\\nRew:{train_rew} \\nSteps per episode:{train_steps_episode} \\nSuccess rate:{train_success_rate}%\\n\"\"\")\n",
    "\n",
    "        if 'evaluation' in result:\n",
    "            testing_rew = round(result['evaluation']['env_runners']['episode_return_mean'], 2)\n",
    "            testing_steps_episode = round(result['evaluation']['env_runners']['episode_len_mean'], 2)\n",
    "            testing_success_rate = round(result['evaluation']['env_runners']['custom_metrics'].get('success_rate_mean', 0), 2) * 100\n",
    "            print(f\"\"\"TESTING\\nRew:{testing_rew} \\nSteps per episode:{testing_steps_episode} \\nSuccess rate:{testing_success_rate}%\\n\\n\"\"\")\n",
    "\n",
    "        log_data = {\n",
    "            \"Episodes\": num_total_episodes,\n",
    "\n",
    "            \"Training_steps_per_episode\": train_steps_episode,\n",
    "            \"Training_success_rate_per_episode\": train_success_rate,\n",
    "            \"Training_reward_per_episode\": train_rew,\n",
    "\n",
    "            \"Testing_steps_per_episode\": testing_steps_episode,\n",
    "            \"Testing_success_rate_per_episode\": testing_success_rate,\n",
    "            \"Testing_reward_per_episode\": testing_rew\n",
    "        }\n",
    "        wandb.log(log_data)\n",
    "    save_model(ppo, file_name)\n",
    "    wandb.finish()\n",
    "\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec15527",
   "metadata": {},
   "source": [
    "## **Save the agents model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd783a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_model(ppo, file_name):\n",
    "    current_dir = os.getcwd()\n",
    "    model_dir = os.path.join(current_dir, \"models\")\n",
    "    checkpoint_name = os.path.join(model_dir, file_name)\n",
    "    ppo.save(checkpoint_name)\n",
    "\n",
    "    print(f\"Model saved into {checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3738be",
   "metadata": {},
   "source": [
    "## **Load agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2029a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPO\n",
    "import os\n",
    "\n",
    "def load_model(file_name):\n",
    "    current_dir = os.getcwd()\n",
    "    model_dir = os.path.join(current_dir, \"models\")\n",
    "    checkpoint_name = os.path.join(model_dir, file_name)\n",
    "\n",
    "    ppo = PPO.from_checkpoint(checkpoint_name)\n",
    "    return ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "model_dir = os.path.join(current_dir, \"models\")\n",
    "\n",
    "for filename in os.listdir(model_dir):\n",
    "    if \"best\" in filename and under_examination in filename:\n",
    "        matching_file = filename\n",
    "        break\n",
    "\n",
    "file_path = os.path.join(model_dir, matching_file)\n",
    "ppo = load_model(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c4cf2",
   "metadata": {},
   "source": [
    "## **Graphically test the agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ae26d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Sprite image /home/terra/Desktop/unimore/distributed_project/sprites/.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image /home/terra/Desktop/unimore/distributed_project/sprites/.png not found. Using default sprite for this simulation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 11:56:25,238\tWARNING 2186136998.py:10 -- DeprecationWarning: `compute_single_action` has been deprecated. `Algorithm.compute_single_action` should no longer be used. Get the RLModule instance through `Algorithm.get_module([module ID])`, then compute actions through `RLModule.forward_inference({'obs': [obs batch]})`. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "POLICY_ID = \"shared_policy\" \n",
    "\n",
    "env = MyGridWorld(grid_size=15, n_agents=2, render_mode=\"human\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "i = 0\n",
    "while i<3:\n",
    "    actions = {}\n",
    "    for agent_id, agent_obs in obs.items():\n",
    "        actions[agent_id] = ppo.compute_single_action(\n",
    "            agent_obs, \n",
    "            policy_id=POLICY_ID,\n",
    "            explore=False\n",
    "        )\n",
    "    \n",
    "    obs, rewards, terminations, truncations, infos = env.step(actions)\n",
    "\n",
    "    if any(terminations.values()) or any(truncations.values()):\n",
    "        obs, _ = env.reset()\n",
    "        i+=1\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MARL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
