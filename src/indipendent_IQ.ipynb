{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c740894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IQ import train_agents, test_agents, IQLearningAgent\n",
    "from myenv_5_sparse_reward import MyGridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbbcc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set /distributed_project as working directory: /home/terra/Desktop/unimore/distributed_project\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_path = Path.cwd()\n",
    "project_root = None\n",
    "for parent in [current_path] + list(current_path.parents):\n",
    "    if parent.name == \"distributed_project\":\n",
    "        project_root = parent\n",
    "        break\n",
    "os.chdir(project_root)\n",
    "print(f\"Set /distributed_project as working directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de695093",
   "metadata": {},
   "source": [
    "## Train in a gridworld 9x9 (actually 7x3)\n",
    "Number of possible states: (7*3)* (7*3-1)*2 = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57f9dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agnets: ['agent1', 'agent2']\n",
      "Observation space: 7\n",
      "Action space: 5\n",
      "========================================\n",
      "IQ TRAINING PHASE\n",
      "Num training episodes: 10000\n",
      "Espilon decaying rate: 0.9995\n",
      "========================================\n",
      "Episode 0/10000, Epsilon: 1.000, Episode joint_total_reward: -392\n",
      "Episode 100/10000, Epsilon: 0.951, Episode joint_total_reward: -386\n",
      "Episode 200/10000, Epsilon: 0.904, Episode joint_total_reward: -378\n",
      "Episode 300/10000, Epsilon: 0.860, Episode joint_total_reward: 198\n",
      "Episode 400/10000, Epsilon: 0.818, Episode joint_total_reward: -356\n",
      "Episode 500/10000, Epsilon: 0.778, Episode joint_total_reward: -344\n",
      "Episode 600/10000, Epsilon: 0.740, Episode joint_total_reward: 110\n",
      "Episode 700/10000, Epsilon: 0.704, Episode joint_total_reward: -326\n",
      "Episode 800/10000, Epsilon: 0.670, Episode joint_total_reward: -314\n",
      "Episode 900/10000, Epsilon: 0.637, Episode joint_total_reward: -314\n",
      "Episode 1000/10000, Epsilon: 0.606, Episode joint_total_reward: -274\n",
      "Episode 1100/10000, Epsilon: 0.577, Episode joint_total_reward: -300\n",
      "Episode 1200/10000, Epsilon: 0.548, Episode joint_total_reward: 64\n",
      "Episode 1300/10000, Epsilon: 0.522, Episode joint_total_reward: 144\n",
      "Episode 1400/10000, Epsilon: 0.496, Episode joint_total_reward: -320\n",
      "Episode 1500/10000, Epsilon: 0.472, Episode joint_total_reward: 96\n",
      "Episode 1600/10000, Epsilon: 0.449, Episode joint_total_reward: -306\n",
      "Episode 1700/10000, Epsilon: 0.427, Episode joint_total_reward: -296\n",
      "Episode 1800/10000, Epsilon: 0.406, Episode joint_total_reward: 154\n",
      "Episode 1900/10000, Epsilon: 0.386, Episode joint_total_reward: 184\n",
      "Episode 2000/10000, Epsilon: 0.368, Episode joint_total_reward: 178\n",
      "Episode 2100/10000, Epsilon: 0.350, Episode joint_total_reward: 192\n",
      "Episode 2200/10000, Epsilon: 0.333, Episode joint_total_reward: 138\n",
      "Episode 2300/10000, Epsilon: 0.316, Episode joint_total_reward: 194\n",
      "Episode 2400/10000, Epsilon: 0.301, Episode joint_total_reward: 172\n",
      "Episode 2500/10000, Epsilon: 0.286, Episode joint_total_reward: 138\n",
      "Episode 2600/10000, Epsilon: 0.272, Episode joint_total_reward: 156\n",
      "Episode 2700/10000, Epsilon: 0.259, Episode joint_total_reward: 192\n",
      "Episode 2800/10000, Epsilon: 0.246, Episode joint_total_reward: 158\n",
      "Episode 2900/10000, Epsilon: 0.234, Episode joint_total_reward: 188\n",
      "Episode 3000/10000, Epsilon: 0.223, Episode joint_total_reward: 190\n",
      "Episode 3100/10000, Epsilon: 0.212, Episode joint_total_reward: 172\n",
      "Episode 3200/10000, Epsilon: 0.202, Episode joint_total_reward: 198\n",
      "Episode 3300/10000, Epsilon: 0.192, Episode joint_total_reward: 192\n",
      "Episode 3400/10000, Epsilon: 0.183, Episode joint_total_reward: 198\n",
      "Episode 3500/10000, Epsilon: 0.174, Episode joint_total_reward: 190\n",
      "Episode 3600/10000, Epsilon: 0.165, Episode joint_total_reward: 188\n",
      "Episode 3700/10000, Epsilon: 0.157, Episode joint_total_reward: 178\n",
      "Episode 3800/10000, Epsilon: 0.149, Episode joint_total_reward: 200\n",
      "Episode 3900/10000, Epsilon: 0.142, Episode joint_total_reward: 184\n",
      "Episode 4000/10000, Epsilon: 0.135, Episode joint_total_reward: 194\n",
      "Episode 4100/10000, Epsilon: 0.129, Episode joint_total_reward: 196\n",
      "Episode 4200/10000, Epsilon: 0.122, Episode joint_total_reward: 192\n",
      "Episode 4300/10000, Epsilon: 0.116, Episode joint_total_reward: 174\n",
      "Episode 4400/10000, Epsilon: 0.111, Episode joint_total_reward: 192\n",
      "Episode 4500/10000, Epsilon: 0.105, Episode joint_total_reward: 196\n",
      "Episode 4600/10000, Epsilon: 0.100, Episode joint_total_reward: 196\n",
      "Episode 4700/10000, Epsilon: 0.095, Episode joint_total_reward: 200\n",
      "Episode 4800/10000, Epsilon: 0.091, Episode joint_total_reward: 198\n",
      "Episode 4900/10000, Epsilon: 0.086, Episode joint_total_reward: 198\n",
      "Episode 5000/10000, Epsilon: 0.082, Episode joint_total_reward: 188\n",
      "Episode 5100/10000, Epsilon: 0.078, Episode joint_total_reward: 196\n",
      "Episode 5200/10000, Epsilon: 0.074, Episode joint_total_reward: 200\n",
      "Episode 5300/10000, Epsilon: 0.071, Episode joint_total_reward: 200\n",
      "Episode 5400/10000, Epsilon: 0.067, Episode joint_total_reward: 196\n",
      "Episode 5500/10000, Epsilon: 0.064, Episode joint_total_reward: 194\n",
      "Episode 5600/10000, Epsilon: 0.061, Episode joint_total_reward: 194\n",
      "Episode 5700/10000, Epsilon: 0.058, Episode joint_total_reward: 196\n",
      "Episode 5800/10000, Epsilon: 0.055, Episode joint_total_reward: 200\n",
      "Episode 5900/10000, Epsilon: 0.052, Episode joint_total_reward: 192\n",
      "Episode 6000/10000, Epsilon: 0.050, Episode joint_total_reward: 194\n",
      "Episode 6100/10000, Epsilon: 0.047, Episode joint_total_reward: 200\n",
      "Episode 6200/10000, Epsilon: 0.045, Episode joint_total_reward: 192\n",
      "Episode 6300/10000, Epsilon: 0.043, Episode joint_total_reward: 196\n",
      "Episode 6400/10000, Epsilon: 0.041, Episode joint_total_reward: 196\n",
      "Episode 6500/10000, Epsilon: 0.039, Episode joint_total_reward: 194\n",
      "Episode 6600/10000, Epsilon: 0.037, Episode joint_total_reward: 200\n",
      "Episode 6700/10000, Epsilon: 0.035, Episode joint_total_reward: 194\n",
      "Episode 6800/10000, Epsilon: 0.033, Episode joint_total_reward: 198\n",
      "Episode 6900/10000, Epsilon: 0.032, Episode joint_total_reward: 194\n",
      "Episode 7000/10000, Epsilon: 0.030, Episode joint_total_reward: 196\n",
      "Episode 7100/10000, Epsilon: 0.029, Episode joint_total_reward: 200\n",
      "Episode 7200/10000, Epsilon: 0.027, Episode joint_total_reward: 196\n",
      "Episode 7300/10000, Epsilon: 0.026, Episode joint_total_reward: 200\n",
      "Episode 7400/10000, Epsilon: 0.025, Episode joint_total_reward: 200\n",
      "Episode 7500/10000, Epsilon: 0.023, Episode joint_total_reward: 198\n",
      "Episode 7600/10000, Epsilon: 0.022, Episode joint_total_reward: 194\n",
      "Episode 7700/10000, Epsilon: 0.021, Episode joint_total_reward: 196\n",
      "Episode 7800/10000, Epsilon: 0.020, Episode joint_total_reward: 198\n",
      "Episode 7900/10000, Epsilon: 0.019, Episode joint_total_reward: 198\n",
      "Episode 8000/10000, Epsilon: 0.018, Episode joint_total_reward: 192\n",
      "Episode 8100/10000, Epsilon: 0.017, Episode joint_total_reward: 190\n",
      "Episode 8200/10000, Epsilon: 0.017, Episode joint_total_reward: 196\n",
      "Episode 8300/10000, Epsilon: 0.016, Episode joint_total_reward: 196\n",
      "Episode 8400/10000, Epsilon: 0.015, Episode joint_total_reward: 196\n",
      "Episode 8500/10000, Epsilon: 0.014, Episode joint_total_reward: 198\n",
      "Episode 8600/10000, Epsilon: 0.014, Episode joint_total_reward: 190\n",
      "Episode 8700/10000, Epsilon: 0.013, Episode joint_total_reward: 198\n",
      "Episode 8800/10000, Epsilon: 0.012, Episode joint_total_reward: 196\n",
      "Episode 8900/10000, Epsilon: 0.012, Episode joint_total_reward: 200\n",
      "Episode 9000/10000, Epsilon: 0.011, Episode joint_total_reward: 196\n",
      "Episode 9100/10000, Epsilon: 0.011, Episode joint_total_reward: 194\n",
      "Episode 9200/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9300/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9400/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9500/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9600/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9700/10000, Epsilon: 0.010, Episode joint_total_reward: 194\n",
      "Episode 9800/10000, Epsilon: 0.010, Episode joint_total_reward: 192\n",
      "Episode 9900/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "END OF IQ TRAINING PHASE\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 9\n",
    "\n",
    "env = MyGridWorld(grid_size=GRID_SIZE)\n",
    "agents = {}\n",
    "action_size = env.action_space(\"agent1\").n\n",
    "obs_shape = env.observation_space(\"agent1\").shape[0]\n",
    "\n",
    "print(f\"Agnets: {env.possible_agents}\\nObservation space: {obs_shape}\\nAction space: {action_size}\")\n",
    "\n",
    "for agent_id in env.possible_agents:\n",
    "    agents[agent_id] = IQLearningAgent(\n",
    "        agent_id=agent_id, \n",
    "        action_space_size=action_size, \n",
    "        obs_space_shape=obs_shape,\n",
    "        learning_rate=0.1, \n",
    "        discount_factor=0.85,\n",
    "        epsilon=1 # High initial exploration\n",
    "    )\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "EPSILON_DECAY_RATE = 0.9995\n",
    "MIN_EPSILON = 0.01\n",
    "\n",
    "# TRAINING \n",
    "trained_agents = train_agents(\n",
    "    env, \n",
    "    agents, \n",
    "    NUM_EPISODES, \n",
    "    EPSILON_DECAY_RATE, \n",
    "    MIN_EPSILON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fc876fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "IQ TEST PHASE\n",
      "Num testing episodes: 100\n",
      "========================================\n",
      "Test Ep. 1/100: Status=SUCCESS, Reward=196.00, Steps=4\n",
      "Test Ep. 21/100: Status=SUCCESS, Reward=198.00, Steps=5\n",
      "Test Ep. 41/100: Status=SUCCESS, Reward=196.00, Steps=4\n",
      "Test Ep. 61/100: Status=SUCCESS, Reward=194.00, Steps=7\n",
      "Test Ep. 81/100: Status=SUCCESS, Reward=200.00, Steps=5\n",
      "END OF IQ TESTING PHASE\n",
      "\n",
      "========================================\n",
      "TEST METRICS\n",
      "Success rate: 100.00%\n",
      "Avg reward per episode: 196.70\n",
      "Avg steps per episode: 4.99\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "env_test = MyGridWorld(grid_size=GRID_SIZE) \n",
    "test_agents(env_test, trained_agents, num_test_episodes=100)\n",
    "\n",
    "env.close()\n",
    "env_test.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406bf57",
   "metadata": {},
   "source": [
    "## Train in a gridworld 10x10 (actually 8x4)\n",
    "Number of possible states: (8*4)* (8*4-1)*2 = 1984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "105d49d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agnets: ['agent1', 'agent2']\n",
      "Observation space: 7\n",
      "Action space: 5\n",
      "========================================\n",
      "IQ TRAINING PHASE\n",
      "Num training episodes: 10000\n",
      "Espilon decaying rate: 0.9995\n",
      "========================================\n",
      "Episode 0/10000, Epsilon: 1.000, Episode joint_total_reward: -384\n",
      "Episode 100/10000, Epsilon: 0.951, Episode joint_total_reward: -390\n",
      "Episode 200/10000, Epsilon: 0.904, Episode joint_total_reward: -396\n",
      "Episode 300/10000, Epsilon: 0.860, Episode joint_total_reward: -398\n",
      "Episode 400/10000, Epsilon: 0.818, Episode joint_total_reward: -376\n",
      "Episode 500/10000, Epsilon: 0.778, Episode joint_total_reward: -358\n",
      "Episode 600/10000, Epsilon: 0.740, Episode joint_total_reward: -306\n",
      "Episode 700/10000, Epsilon: 0.704, Episode joint_total_reward: 194\n",
      "Episode 800/10000, Epsilon: 0.670, Episode joint_total_reward: -350\n",
      "Episode 900/10000, Epsilon: 0.637, Episode joint_total_reward: -332\n",
      "Episode 1000/10000, Epsilon: 0.606, Episode joint_total_reward: 126\n",
      "Episode 1100/10000, Epsilon: 0.577, Episode joint_total_reward: -348\n",
      "Episode 1200/10000, Epsilon: 0.548, Episode joint_total_reward: -336\n",
      "Episode 1300/10000, Epsilon: 0.522, Episode joint_total_reward: -330\n",
      "Episode 1400/10000, Epsilon: 0.496, Episode joint_total_reward: -344\n",
      "Episode 1500/10000, Epsilon: 0.472, Episode joint_total_reward: -362\n",
      "Episode 1600/10000, Epsilon: 0.449, Episode joint_total_reward: -328\n",
      "Episode 1700/10000, Epsilon: 0.427, Episode joint_total_reward: -344\n",
      "Episode 1800/10000, Epsilon: 0.406, Episode joint_total_reward: -304\n",
      "Episode 1900/10000, Epsilon: 0.386, Episode joint_total_reward: 152\n",
      "Episode 2000/10000, Epsilon: 0.368, Episode joint_total_reward: 86\n",
      "Episode 2100/10000, Epsilon: 0.350, Episode joint_total_reward: 176\n",
      "Episode 2200/10000, Epsilon: 0.333, Episode joint_total_reward: 154\n",
      "Episode 2300/10000, Epsilon: 0.316, Episode joint_total_reward: 162\n",
      "Episode 2400/10000, Epsilon: 0.301, Episode joint_total_reward: 136\n",
      "Episode 2500/10000, Epsilon: 0.286, Episode joint_total_reward: -310\n",
      "Episode 2600/10000, Epsilon: 0.272, Episode joint_total_reward: -380\n",
      "Episode 2700/10000, Epsilon: 0.259, Episode joint_total_reward: 64\n",
      "Episode 2800/10000, Epsilon: 0.246, Episode joint_total_reward: -348\n",
      "Episode 2900/10000, Epsilon: 0.234, Episode joint_total_reward: 56\n",
      "Episode 3000/10000, Epsilon: 0.223, Episode joint_total_reward: 152\n",
      "Episode 3100/10000, Epsilon: 0.212, Episode joint_total_reward: -332\n",
      "Episode 3200/10000, Epsilon: 0.202, Episode joint_total_reward: 138\n",
      "Episode 3300/10000, Epsilon: 0.192, Episode joint_total_reward: 146\n",
      "Episode 3400/10000, Epsilon: 0.183, Episode joint_total_reward: -388\n",
      "Episode 3500/10000, Epsilon: 0.174, Episode joint_total_reward: -396\n",
      "Episode 3600/10000, Epsilon: 0.165, Episode joint_total_reward: -362\n",
      "Episode 3700/10000, Epsilon: 0.157, Episode joint_total_reward: -384\n",
      "Episode 3800/10000, Epsilon: 0.149, Episode joint_total_reward: -380\n",
      "Episode 3900/10000, Epsilon: 0.142, Episode joint_total_reward: -398\n",
      "Episode 4000/10000, Epsilon: 0.135, Episode joint_total_reward: -392\n",
      "Episode 4100/10000, Epsilon: 0.129, Episode joint_total_reward: -368\n",
      "Episode 4200/10000, Epsilon: 0.122, Episode joint_total_reward: -398\n",
      "Episode 4300/10000, Epsilon: 0.116, Episode joint_total_reward: -394\n",
      "Episode 4400/10000, Epsilon: 0.111, Episode joint_total_reward: -364\n",
      "Episode 4500/10000, Epsilon: 0.105, Episode joint_total_reward: 182\n",
      "Episode 4600/10000, Epsilon: 0.100, Episode joint_total_reward: -388\n",
      "Episode 4700/10000, Epsilon: 0.095, Episode joint_total_reward: -398\n",
      "Episode 4800/10000, Epsilon: 0.091, Episode joint_total_reward: -376\n",
      "Episode 4900/10000, Epsilon: 0.086, Episode joint_total_reward: -388\n",
      "Episode 5000/10000, Epsilon: 0.082, Episode joint_total_reward: -392\n",
      "Episode 5100/10000, Epsilon: 0.078, Episode joint_total_reward: -388\n",
      "Episode 5200/10000, Epsilon: 0.074, Episode joint_total_reward: -396\n",
      "Episode 5300/10000, Epsilon: 0.071, Episode joint_total_reward: -358\n",
      "Episode 5400/10000, Epsilon: 0.067, Episode joint_total_reward: -358\n",
      "Episode 5500/10000, Epsilon: 0.064, Episode joint_total_reward: -382\n",
      "Episode 5600/10000, Epsilon: 0.061, Episode joint_total_reward: -368\n",
      "Episode 5700/10000, Epsilon: 0.058, Episode joint_total_reward: -360\n",
      "Episode 5800/10000, Epsilon: 0.055, Episode joint_total_reward: -390\n",
      "Episode 5900/10000, Epsilon: 0.052, Episode joint_total_reward: -382\n",
      "Episode 6000/10000, Epsilon: 0.050, Episode joint_total_reward: -398\n",
      "Episode 6100/10000, Epsilon: 0.047, Episode joint_total_reward: -386\n",
      "Episode 6200/10000, Epsilon: 0.045, Episode joint_total_reward: -374\n",
      "Episode 6300/10000, Epsilon: 0.043, Episode joint_total_reward: -390\n",
      "Episode 6400/10000, Epsilon: 0.041, Episode joint_total_reward: -398\n",
      "Episode 6500/10000, Epsilon: 0.039, Episode joint_total_reward: -390\n",
      "Episode 6600/10000, Epsilon: 0.037, Episode joint_total_reward: -362\n",
      "Episode 6700/10000, Epsilon: 0.035, Episode joint_total_reward: -368\n",
      "Episode 6800/10000, Epsilon: 0.033, Episode joint_total_reward: -398\n",
      "Episode 6900/10000, Epsilon: 0.032, Episode joint_total_reward: 182\n",
      "Episode 7000/10000, Epsilon: 0.030, Episode joint_total_reward: 196\n",
      "Episode 7100/10000, Epsilon: 0.029, Episode joint_total_reward: 154\n",
      "Episode 7200/10000, Epsilon: 0.027, Episode joint_total_reward: -390\n",
      "Episode 7300/10000, Epsilon: 0.026, Episode joint_total_reward: -372\n",
      "Episode 7400/10000, Epsilon: 0.025, Episode joint_total_reward: -392\n",
      "Episode 7500/10000, Epsilon: 0.023, Episode joint_total_reward: 168\n",
      "Episode 7600/10000, Epsilon: 0.022, Episode joint_total_reward: -396\n",
      "Episode 7700/10000, Epsilon: 0.021, Episode joint_total_reward: 176\n",
      "Episode 7800/10000, Epsilon: 0.020, Episode joint_total_reward: -392\n",
      "Episode 7900/10000, Epsilon: 0.019, Episode joint_total_reward: -380\n",
      "Episode 8000/10000, Epsilon: 0.018, Episode joint_total_reward: 200\n",
      "Episode 8100/10000, Epsilon: 0.017, Episode joint_total_reward: -334\n",
      "Episode 8200/10000, Epsilon: 0.017, Episode joint_total_reward: -394\n",
      "Episode 8300/10000, Epsilon: 0.016, Episode joint_total_reward: 68\n",
      "Episode 8400/10000, Epsilon: 0.015, Episode joint_total_reward: -398\n",
      "Episode 8500/10000, Epsilon: 0.014, Episode joint_total_reward: -328\n",
      "Episode 8600/10000, Epsilon: 0.014, Episode joint_total_reward: 152\n",
      "Episode 8700/10000, Epsilon: 0.013, Episode joint_total_reward: -310\n",
      "Episode 8800/10000, Epsilon: 0.012, Episode joint_total_reward: 100\n",
      "Episode 8900/10000, Epsilon: 0.012, Episode joint_total_reward: -364\n",
      "Episode 9000/10000, Epsilon: 0.011, Episode joint_total_reward: 138\n",
      "Episode 9100/10000, Epsilon: 0.011, Episode joint_total_reward: -372\n",
      "Episode 9200/10000, Epsilon: 0.010, Episode joint_total_reward: 106\n",
      "Episode 9300/10000, Epsilon: 0.010, Episode joint_total_reward: -368\n",
      "Episode 9400/10000, Epsilon: 0.010, Episode joint_total_reward: 156\n",
      "Episode 9500/10000, Epsilon: 0.010, Episode joint_total_reward: 170\n",
      "Episode 9600/10000, Epsilon: 0.010, Episode joint_total_reward: -358\n",
      "Episode 9700/10000, Epsilon: 0.010, Episode joint_total_reward: 188\n",
      "Episode 9800/10000, Epsilon: 0.010, Episode joint_total_reward: 140\n",
      "Episode 9900/10000, Epsilon: 0.010, Episode joint_total_reward: 134\n",
      "END OF IQ TRAINING PHASE\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 10\n",
    "\n",
    "env = MyGridWorld(grid_size=GRID_SIZE)\n",
    "agents = {}\n",
    "action_size = env.action_space(\"agent1\").n\n",
    "obs_shape = env.observation_space(\"agent1\").shape[0]\n",
    "\n",
    "print(f\"Agnets: {env.possible_agents}\\nObservation space: {obs_shape}\\nAction space: {action_size}\")\n",
    "\n",
    "for agent_id in env.possible_agents:\n",
    "    agents[agent_id] = IQLearningAgent(\n",
    "        agent_id=agent_id, \n",
    "        action_space_size=action_size, \n",
    "        obs_space_shape=obs_shape,\n",
    "        learning_rate=0.1, \n",
    "        discount_factor=0.85,\n",
    "        epsilon=1 # High initial exploration\n",
    "    )\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "EPSILON_DECAY_RATE = 0.9995\n",
    "MIN_EPSILON = 0.01\n",
    "\n",
    "# TRAINING \n",
    "trained_agents = train_agents(\n",
    "    env, \n",
    "    agents, \n",
    "    NUM_EPISODES, \n",
    "    EPSILON_DECAY_RATE, \n",
    "    MIN_EPSILON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fc411e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "IQ TEST PHASE\n",
      "Num testing episodes: 100\n",
      "========================================\n",
      "Test Ep. 1/100: Status=SUCCESS, Reward=156.00, Steps=24\n",
      "Test Ep. 21/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "Test Ep. 41/100: Status=SUCCESS, Reward=164.00, Steps=20\n",
      "Test Ep. 61/100: Status=SUCCESS, Reward=136.00, Steps=42\n",
      "Test Ep. 81/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "END OF IQ TESTING PHASE\n",
      "\n",
      "========================================\n",
      "TEST METRICS\n",
      "Success rate: 88.00%\n",
      "Avg reward per episode: 92.50\n",
      "Avg steps per episode: 33.27\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "env_test = MyGridWorld(grid_size=GRID_SIZE) \n",
    "test_agents(env_test, trained_agents, num_test_episodes=100)\n",
    "\n",
    "env.close()\n",
    "env_test.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d5d32",
   "metadata": {},
   "source": [
    "## Train in a gridworld 11x11 (actually 9x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb122099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agnets: ['agent1', 'agent2']\n",
      "Observation space: 7\n",
      "Action space: 5\n",
      "========================================\n",
      "IQ TRAINING PHASE\n",
      "Num training episodes: 10000\n",
      "Espilon decaying rate: 0.9995\n",
      "========================================\n",
      "Episode 0/10000, Epsilon: 1.000, Episode joint_total_reward: -384\n",
      "Episode 100/10000, Epsilon: 0.951, Episode joint_total_reward: -388\n",
      "Episode 200/10000, Epsilon: 0.904, Episode joint_total_reward: -394\n",
      "Episode 300/10000, Epsilon: 0.860, Episode joint_total_reward: -366\n",
      "Episode 400/10000, Epsilon: 0.818, Episode joint_total_reward: -386\n",
      "Episode 500/10000, Epsilon: 0.778, Episode joint_total_reward: -398\n",
      "Episode 600/10000, Epsilon: 0.740, Episode joint_total_reward: -398\n",
      "Episode 700/10000, Epsilon: 0.704, Episode joint_total_reward: -338\n",
      "Episode 800/10000, Epsilon: 0.670, Episode joint_total_reward: -370\n",
      "Episode 900/10000, Epsilon: 0.637, Episode joint_total_reward: -366\n",
      "Episode 1000/10000, Epsilon: 0.606, Episode joint_total_reward: -332\n",
      "Episode 1100/10000, Epsilon: 0.577, Episode joint_total_reward: -398\n",
      "Episode 1200/10000, Epsilon: 0.548, Episode joint_total_reward: -360\n",
      "Episode 1300/10000, Epsilon: 0.522, Episode joint_total_reward: -332\n",
      "Episode 1400/10000, Epsilon: 0.496, Episode joint_total_reward: -354\n",
      "Episode 1500/10000, Epsilon: 0.472, Episode joint_total_reward: -324\n",
      "Episode 1600/10000, Epsilon: 0.449, Episode joint_total_reward: -382\n",
      "Episode 1700/10000, Epsilon: 0.427, Episode joint_total_reward: 108\n",
      "Episode 1800/10000, Epsilon: 0.406, Episode joint_total_reward: -346\n",
      "Episode 1900/10000, Epsilon: 0.386, Episode joint_total_reward: 180\n",
      "Episode 2000/10000, Epsilon: 0.368, Episode joint_total_reward: -356\n",
      "Episode 2100/10000, Epsilon: 0.350, Episode joint_total_reward: -342\n",
      "Episode 2200/10000, Epsilon: 0.333, Episode joint_total_reward: -370\n",
      "Episode 2300/10000, Epsilon: 0.316, Episode joint_total_reward: 92\n",
      "Episode 2400/10000, Epsilon: 0.301, Episode joint_total_reward: -312\n",
      "Episode 2500/10000, Epsilon: 0.286, Episode joint_total_reward: -332\n",
      "Episode 2600/10000, Epsilon: 0.272, Episode joint_total_reward: -368\n",
      "Episode 2700/10000, Epsilon: 0.259, Episode joint_total_reward: -338\n",
      "Episode 2800/10000, Epsilon: 0.246, Episode joint_total_reward: -374\n",
      "Episode 2900/10000, Epsilon: 0.234, Episode joint_total_reward: -316\n",
      "Episode 3000/10000, Epsilon: 0.223, Episode joint_total_reward: -340\n",
      "Episode 3100/10000, Epsilon: 0.212, Episode joint_total_reward: -376\n",
      "Episode 3200/10000, Epsilon: 0.202, Episode joint_total_reward: -368\n",
      "Episode 3300/10000, Epsilon: 0.192, Episode joint_total_reward: -370\n",
      "Episode 3400/10000, Epsilon: 0.183, Episode joint_total_reward: -380\n",
      "Episode 3500/10000, Epsilon: 0.174, Episode joint_total_reward: -368\n",
      "Episode 3600/10000, Epsilon: 0.165, Episode joint_total_reward: -388\n",
      "Episode 3700/10000, Epsilon: 0.157, Episode joint_total_reward: -376\n",
      "Episode 3800/10000, Epsilon: 0.149, Episode joint_total_reward: -390\n",
      "Episode 3900/10000, Epsilon: 0.142, Episode joint_total_reward: -398\n",
      "Episode 4000/10000, Epsilon: 0.135, Episode joint_total_reward: -370\n",
      "Episode 4100/10000, Epsilon: 0.129, Episode joint_total_reward: -398\n",
      "Episode 4200/10000, Epsilon: 0.122, Episode joint_total_reward: -388\n",
      "Episode 4300/10000, Epsilon: 0.116, Episode joint_total_reward: -372\n",
      "Episode 4400/10000, Epsilon: 0.111, Episode joint_total_reward: -382\n",
      "Episode 4500/10000, Epsilon: 0.105, Episode joint_total_reward: -392\n",
      "Episode 4600/10000, Epsilon: 0.100, Episode joint_total_reward: -386\n",
      "Episode 4700/10000, Epsilon: 0.095, Episode joint_total_reward: -390\n",
      "Episode 4800/10000, Epsilon: 0.091, Episode joint_total_reward: -390\n",
      "Episode 4900/10000, Epsilon: 0.086, Episode joint_total_reward: -398\n",
      "Episode 5000/10000, Epsilon: 0.082, Episode joint_total_reward: -386\n",
      "Episode 5100/10000, Epsilon: 0.078, Episode joint_total_reward: -386\n",
      "Episode 5200/10000, Epsilon: 0.074, Episode joint_total_reward: 92\n",
      "Episode 5300/10000, Epsilon: 0.071, Episode joint_total_reward: 150\n",
      "Episode 5400/10000, Epsilon: 0.067, Episode joint_total_reward: -394\n",
      "Episode 5500/10000, Epsilon: 0.064, Episode joint_total_reward: -382\n",
      "Episode 5600/10000, Epsilon: 0.061, Episode joint_total_reward: -398\n",
      "Episode 5700/10000, Epsilon: 0.058, Episode joint_total_reward: -392\n",
      "Episode 5800/10000, Epsilon: 0.055, Episode joint_total_reward: 132\n",
      "Episode 5900/10000, Epsilon: 0.052, Episode joint_total_reward: -364\n",
      "Episode 6000/10000, Epsilon: 0.050, Episode joint_total_reward: -380\n",
      "Episode 6100/10000, Epsilon: 0.047, Episode joint_total_reward: -394\n",
      "Episode 6200/10000, Epsilon: 0.045, Episode joint_total_reward: -392\n",
      "Episode 6300/10000, Epsilon: 0.043, Episode joint_total_reward: -390\n",
      "Episode 6400/10000, Epsilon: 0.041, Episode joint_total_reward: -396\n",
      "Episode 6500/10000, Epsilon: 0.039, Episode joint_total_reward: -390\n",
      "Episode 6600/10000, Epsilon: 0.037, Episode joint_total_reward: -398\n",
      "Episode 6700/10000, Epsilon: 0.035, Episode joint_total_reward: -388\n",
      "Episode 6800/10000, Epsilon: 0.033, Episode joint_total_reward: -392\n",
      "Episode 6900/10000, Epsilon: 0.032, Episode joint_total_reward: -394\n",
      "Episode 7000/10000, Epsilon: 0.030, Episode joint_total_reward: -388\n",
      "Episode 7100/10000, Epsilon: 0.029, Episode joint_total_reward: -388\n",
      "Episode 7200/10000, Epsilon: 0.027, Episode joint_total_reward: -396\n",
      "Episode 7300/10000, Epsilon: 0.026, Episode joint_total_reward: -394\n",
      "Episode 7400/10000, Epsilon: 0.025, Episode joint_total_reward: -284\n",
      "Episode 7500/10000, Epsilon: 0.023, Episode joint_total_reward: -380\n",
      "Episode 7600/10000, Epsilon: 0.022, Episode joint_total_reward: -398\n",
      "Episode 7700/10000, Epsilon: 0.021, Episode joint_total_reward: -392\n",
      "Episode 7800/10000, Epsilon: 0.020, Episode joint_total_reward: -390\n",
      "Episode 7900/10000, Epsilon: 0.019, Episode joint_total_reward: -386\n",
      "Episode 8000/10000, Epsilon: 0.018, Episode joint_total_reward: -388\n",
      "Episode 8100/10000, Epsilon: 0.017, Episode joint_total_reward: -388\n",
      "Episode 8200/10000, Epsilon: 0.017, Episode joint_total_reward: -380\n",
      "Episode 8300/10000, Epsilon: 0.016, Episode joint_total_reward: -398\n",
      "Episode 8400/10000, Epsilon: 0.015, Episode joint_total_reward: -396\n",
      "Episode 8500/10000, Epsilon: 0.014, Episode joint_total_reward: -384\n",
      "Episode 8600/10000, Epsilon: 0.014, Episode joint_total_reward: -394\n",
      "Episode 8700/10000, Epsilon: 0.013, Episode joint_total_reward: -396\n",
      "Episode 8800/10000, Epsilon: 0.012, Episode joint_total_reward: -390\n",
      "Episode 8900/10000, Epsilon: 0.012, Episode joint_total_reward: -392\n",
      "Episode 9000/10000, Epsilon: 0.011, Episode joint_total_reward: -386\n",
      "Episode 9100/10000, Epsilon: 0.011, Episode joint_total_reward: -384\n",
      "Episode 9200/10000, Epsilon: 0.010, Episode joint_total_reward: -378\n",
      "Episode 9300/10000, Epsilon: 0.010, Episode joint_total_reward: -386\n",
      "Episode 9400/10000, Epsilon: 0.010, Episode joint_total_reward: -396\n",
      "Episode 9500/10000, Epsilon: 0.010, Episode joint_total_reward: -392\n",
      "Episode 9600/10000, Epsilon: 0.010, Episode joint_total_reward: -390\n",
      "Episode 9700/10000, Epsilon: 0.010, Episode joint_total_reward: -388\n",
      "Episode 9800/10000, Epsilon: 0.010, Episode joint_total_reward: -386\n",
      "Episode 9900/10000, Epsilon: 0.010, Episode joint_total_reward: -324\n",
      "END OF IQ TRAINING PHASE\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 11\n",
    "\n",
    "env = MyGridWorld(grid_size=GRID_SIZE)\n",
    "agents = {}\n",
    "action_size = env.action_space(\"agent1\").n\n",
    "obs_shape = env.observation_space(\"agent1\").shape[0]\n",
    "\n",
    "print(f\"Agnets: {env.possible_agents}\\nObservation space: {obs_shape}\\nAction space: {action_size}\")\n",
    "\n",
    "for agent_id in env.possible_agents:\n",
    "    agents[agent_id] = IQLearningAgent(\n",
    "        agent_id=agent_id, \n",
    "        action_space_size=action_size, \n",
    "        obs_space_shape=obs_shape,\n",
    "        learning_rate=0.1, \n",
    "        discount_factor=0.85,\n",
    "        epsilon=1 # High initial exploration\n",
    "    )\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "EPSILON_DECAY_RATE = 0.9995\n",
    "MIN_EPSILON = 0.01\n",
    "\n",
    "# TRAINING \n",
    "trained_agents = train_agents(\n",
    "    env, \n",
    "    agents, \n",
    "    NUM_EPISODES, \n",
    "    EPSILON_DECAY_RATE, \n",
    "    MIN_EPSILON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49c730ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "IQ TEST PHASE\n",
      "Num testing episodes: 100\n",
      "========================================\n",
      "Test Ep. 1/100: Status=TRUNCATED, Reward=-384.00, Steps=100\n",
      "Test Ep. 21/100: Status=TRUNCATED, Reward=-394.00, Steps=100\n",
      "Test Ep. 41/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "Test Ep. 61/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "Test Ep. 81/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "END OF IQ TESTING PHASE\n",
      "\n",
      "========================================\n",
      "TEST METRICS\n",
      "Success rate: 0.00%\n",
      "Avg reward per episode: -387.16\n",
      "Avg steps per episode: 100.00\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "env_test = MyGridWorld(grid_size=GRID_SIZE) \n",
    "test_agents(env_test, trained_agents, num_test_episodes=100)\n",
    "\n",
    "env.close()\n",
    "env_test.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6531983a",
   "metadata": {},
   "source": [
    "# Try with new raward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9b82fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set /distributed_project as working directory: /home/terra/Desktop/unimore/distributed_project\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_path = Path.cwd()\n",
    "project_root = None\n",
    "for parent in [current_path] + list(current_path.parents):\n",
    "    if parent.name == \"distributed_project\":\n",
    "        project_root = parent\n",
    "        break\n",
    "os.chdir(f\"{project_root}/src\")\n",
    "print(f\"Set /distributed_project as working directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11de3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IQ import train_agents, test_agents, IQLearningAgent\n",
    "from myenv_5_dense_reward2 import MyGridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068118c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agnets: ['agent1', 'agent2']\n",
      "Observation space: 7\n",
      "Action space: 5\n",
      "========================================\n",
      "IQ TRAINING PHASE\n",
      "Num training episodes: 10000\n",
      "Espilon decaying rate: 0.9997\n",
      "========================================\n",
      "Episode 0/10000, Epsilon: 1.000, Episode joint_total_reward: -64.50957531163668\n",
      "Episode 100/10000, Epsilon: 0.970, Episode joint_total_reward: -57.6741827843523\n",
      "Episode 200/10000, Epsilon: 0.941, Episode joint_total_reward: -52.43306132842995\n",
      "Episode 300/10000, Epsilon: 0.914, Episode joint_total_reward: -68.36473152464491\n",
      "Episode 400/10000, Epsilon: 0.887, Episode joint_total_reward: -64.14360778170705\n",
      "Episode 500/10000, Epsilon: 0.860, Episode joint_total_reward: -43.67446721602155\n",
      "Episode 600/10000, Epsilon: 0.835, Episode joint_total_reward: -46.12421729062535\n",
      "Episode 700/10000, Epsilon: 0.810, Episode joint_total_reward: -51.022547228726886\n",
      "Episode 800/10000, Epsilon: 0.786, Episode joint_total_reward: -44.13517763705544\n",
      "Episode 900/10000, Epsilon: 0.763, Episode joint_total_reward: -67.1688518254363\n",
      "Episode 1000/10000, Epsilon: 0.741, Episode joint_total_reward: -60.992518981055554\n",
      "Episode 1100/10000, Epsilon: 0.719, Episode joint_total_reward: -37.09744610863564\n",
      "Episode 1200/10000, Epsilon: 0.697, Episode joint_total_reward: -41.00153640966976\n",
      "Episode 1300/10000, Epsilon: 0.677, Episode joint_total_reward: -54.87957653534135\n",
      "Episode 1400/10000, Epsilon: 0.657, Episode joint_total_reward: -31.959467403208695\n",
      "Episode 1500/10000, Epsilon: 0.637, Episode joint_total_reward: -22.400949986163777\n",
      "Episode 1600/10000, Epsilon: 0.619, Episode joint_total_reward: -31.940852954980834\n",
      "Episode 1700/10000, Epsilon: 0.600, Episode joint_total_reward: -14.418542870885398\n",
      "Episode 1800/10000, Epsilon: 0.583, Episode joint_total_reward: -17.977475367429808\n",
      "Episode 1900/10000, Epsilon: 0.565, Episode joint_total_reward: -34.33094310497918\n",
      "Episode 2000/10000, Epsilon: 0.549, Episode joint_total_reward: -18.496403826434623\n",
      "Episode 2100/10000, Epsilon: 0.532, Episode joint_total_reward: -22.981970202802536\n",
      "Episode 2200/10000, Epsilon: 0.517, Episode joint_total_reward: -22.1845169758449\n",
      "Episode 2300/10000, Epsilon: 0.501, Episode joint_total_reward: -17.95242640486202\n",
      "Episode 2400/10000, Epsilon: 0.487, Episode joint_total_reward: -24.9799849506193\n",
      "Episode 2500/10000, Epsilon: 0.472, Episode joint_total_reward: -13.600307183455847\n",
      "Episode 2600/10000, Epsilon: 0.458, Episode joint_total_reward: -14.74082478575368\n",
      "Episode 2700/10000, Epsilon: 0.445, Episode joint_total_reward: -25.674643359313603\n",
      "Episode 2800/10000, Epsilon: 0.432, Episode joint_total_reward: -15.656532995129318\n",
      "Episode 2900/10000, Epsilon: 0.419, Episode joint_total_reward: -18.9110202990201\n",
      "Episode 3000/10000, Epsilon: 0.406, Episode joint_total_reward: -16.427931752081413\n",
      "Episode 3100/10000, Epsilon: 0.394, Episode joint_total_reward: -13.805163874081588\n",
      "Episode 3200/10000, Epsilon: 0.383, Episode joint_total_reward: -20.658912075486658\n",
      "Episode 3300/10000, Epsilon: 0.371, Episode joint_total_reward: -20.23077073494101\n",
      "Episode 3400/10000, Epsilon: 0.360, Episode joint_total_reward: -36.68525920098734\n",
      "Episode 3500/10000, Epsilon: 0.350, Episode joint_total_reward: -26.92785795963805\n",
      "Episode 3600/10000, Epsilon: 0.339, Episode joint_total_reward: -26.901474114141767\n",
      "Episode 3700/10000, Epsilon: 0.329, Episode joint_total_reward: -15.092409821105731\n",
      "Episode 3800/10000, Epsilon: 0.320, Episode joint_total_reward: -12.288862130755222\n",
      "Episode 3900/10000, Epsilon: 0.310, Episode joint_total_reward: -9.632961238225276\n",
      "Episode 4000/10000, Epsilon: 0.301, Episode joint_total_reward: -19.46852049738947\n",
      "Episode 4100/10000, Epsilon: 0.292, Episode joint_total_reward: -10.674011157527747\n",
      "Episode 4200/10000, Epsilon: 0.284, Episode joint_total_reward: -25.812955926951368\n",
      "Episode 4300/10000, Epsilon: 0.275, Episode joint_total_reward: -9.231739002660523\n",
      "Episode 4400/10000, Epsilon: 0.267, Episode joint_total_reward: -10.676605246607597\n",
      "Episode 4500/10000, Epsilon: 0.259, Episode joint_total_reward: 192.376444930366\n",
      "Episode 4600/10000, Epsilon: 0.251, Episode joint_total_reward: -8.520475739808008\n",
      "Episode 4700/10000, Epsilon: 0.244, Episode joint_total_reward: -7.681465120547309\n",
      "Episode 4800/10000, Epsilon: 0.237, Episode joint_total_reward: -13.54663698042364\n",
      "Episode 4900/10000, Epsilon: 0.230, Episode joint_total_reward: 181.92618162559052\n",
      "Episode 5000/10000, Epsilon: 0.223, Episode joint_total_reward: -7.277664948387829\n",
      "Episode 5100/10000, Epsilon: 0.216, Episode joint_total_reward: 197.1303269658953\n",
      "Episode 5200/10000, Epsilon: 0.210, Episode joint_total_reward: 197.0618527998897\n",
      "Episode 5300/10000, Epsilon: 0.204, Episode joint_total_reward: 194.02575655080756\n",
      "Episode 5400/10000, Epsilon: 0.198, Episode joint_total_reward: 196.23049749665478\n",
      "Episode 5500/10000, Epsilon: 0.192, Episode joint_total_reward: -8.808464471741207\n",
      "Episode 5600/10000, Epsilon: 0.186, Episode joint_total_reward: 187.62289099455595\n",
      "Episode 5700/10000, Epsilon: 0.181, Episode joint_total_reward: 172.05619541985197\n",
      "Episode 5800/10000, Epsilon: 0.175, Episode joint_total_reward: 190.15947088767697\n",
      "Episode 5900/10000, Epsilon: 0.170, Episode joint_total_reward: 193.29276479141117\n",
      "Episode 6000/10000, Epsilon: 0.165, Episode joint_total_reward: 190.063662019091\n",
      "Episode 6100/10000, Epsilon: 0.160, Episode joint_total_reward: 193.84627496332564\n",
      "Episode 6200/10000, Epsilon: 0.156, Episode joint_total_reward: 198.3565793117762\n",
      "Episode 6300/10000, Epsilon: 0.151, Episode joint_total_reward: 189.94781672994162\n",
      "Episode 6400/10000, Epsilon: 0.147, Episode joint_total_reward: 196.72810326535554\n",
      "Episode 6500/10000, Epsilon: 0.142, Episode joint_total_reward: 194.66990104603335\n",
      "Episode 6600/10000, Epsilon: 0.138, Episode joint_total_reward: 198.8169514596125\n",
      "Episode 6700/10000, Epsilon: 0.134, Episode joint_total_reward: 199.30605459362855\n",
      "Episode 6800/10000, Epsilon: 0.130, Episode joint_total_reward: 199.69664558301122\n",
      "Episode 6900/10000, Epsilon: 0.126, Episode joint_total_reward: 196.79539885418853\n",
      "Episode 7000/10000, Epsilon: 0.122, Episode joint_total_reward: 199.75759040187083\n",
      "Episode 7100/10000, Epsilon: 0.119, Episode joint_total_reward: 197.30739797067682\n",
      "Episode 7200/10000, Epsilon: 0.115, Episode joint_total_reward: 196.6978027848642\n",
      "Episode 7300/10000, Epsilon: 0.112, Episode joint_total_reward: 190.16751635118572\n",
      "Episode 7400/10000, Epsilon: 0.109, Episode joint_total_reward: 194.87460946844436\n",
      "Episode 7500/10000, Epsilon: 0.105, Episode joint_total_reward: 193.4216826161108\n",
      "Episode 7600/10000, Epsilon: 0.102, Episode joint_total_reward: 199.24151607912577\n",
      "Episode 7700/10000, Epsilon: 0.099, Episode joint_total_reward: 198.58162940147253\n",
      "Episode 7800/10000, Epsilon: 0.096, Episode joint_total_reward: 199.02223682774655\n",
      "Episode 7900/10000, Epsilon: 0.093, Episode joint_total_reward: 196.49536057923936\n",
      "Episode 8000/10000, Epsilon: 0.091, Episode joint_total_reward: 197.33944540641136\n",
      "Episode 8100/10000, Epsilon: 0.088, Episode joint_total_reward: 180.01886885251466\n",
      "Episode 8200/10000, Epsilon: 0.085, Episode joint_total_reward: 181.1203952549977\n",
      "Episode 8300/10000, Epsilon: 0.083, Episode joint_total_reward: 198.70533293083776\n",
      "Episode 8400/10000, Epsilon: 0.080, Episode joint_total_reward: 188.00115504973667\n",
      "Episode 8500/10000, Epsilon: 0.078, Episode joint_total_reward: 194.79150598589652\n",
      "Episode 8600/10000, Epsilon: 0.076, Episode joint_total_reward: 196.53472028650958\n",
      "Episode 8700/10000, Epsilon: 0.073, Episode joint_total_reward: 196.46221687577082\n",
      "Episode 8800/10000, Epsilon: 0.071, Episode joint_total_reward: 199.19586871125705\n",
      "Episode 8900/10000, Epsilon: 0.069, Episode joint_total_reward: 199.57937103014257\n",
      "Episode 9000/10000, Epsilon: 0.067, Episode joint_total_reward: 195.60429602081987\n",
      "Episode 9100/10000, Epsilon: 0.065, Episode joint_total_reward: 198.37708342266293\n",
      "Episode 9200/10000, Epsilon: 0.063, Episode joint_total_reward: 194.5522522767064\n",
      "Episode 9300/10000, Epsilon: 0.061, Episode joint_total_reward: 195.78839477784564\n",
      "Episode 9400/10000, Epsilon: 0.060, Episode joint_total_reward: 198.70313047764694\n",
      "Episode 9500/10000, Epsilon: 0.058, Episode joint_total_reward: 195.07845128525565\n",
      "Episode 9600/10000, Epsilon: 0.056, Episode joint_total_reward: 197.9392805659943\n",
      "Episode 9700/10000, Epsilon: 0.054, Episode joint_total_reward: 197.72351343324257\n",
      "Episode 9800/10000, Epsilon: 0.053, Episode joint_total_reward: 189.94405075704842\n",
      "Episode 9900/10000, Epsilon: 0.051, Episode joint_total_reward: 197.55932307642263\n",
      "END OF IQ TRAINING PHASE\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 13\n",
    "\n",
    "env = MyGridWorld(grid_size=GRID_SIZE)\n",
    "agents = {}\n",
    "action_size = env.action_space(\"agent1\").n\n",
    "obs_shape = env.observation_space(\"agent1\").shape[0]\n",
    "\n",
    "print(f\"Agnets: {env.possible_agents}\\nObservation space: {obs_shape}\\nAction space: {action_size}\")\n",
    "\n",
    "for agent_id in env.possible_agents:\n",
    "    agents[agent_id] = IQLearningAgent(\n",
    "        agent_id=agent_id, \n",
    "        action_space_size=action_size, \n",
    "        obs_space_shape=obs_shape,\n",
    "        learning_rate=0.1, \n",
    "        discount_factor=0.9,\n",
    "        epsilon=1 # High initial exploration\n",
    "    )\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "EPSILON_DECAY_RATE = 0.9997\n",
    "MIN_EPSILON = 0.01\n",
    "\n",
    "# TRAINING \n",
    "trained_agents = train_agents(\n",
    "    env, \n",
    "    agents, \n",
    "    NUM_EPISODES, \n",
    "    EPSILON_DECAY_RATE, \n",
    "    MIN_EPSILON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad07cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "IQ TEST PHASE\n",
      "Num testing episodes: 100\n",
      "========================================\n",
      "WARNING! Sprite image ./sprites/.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/button.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/gate_open.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image ./sprites/gate_close.png not found. Using default sprite for this simulation.\n",
      "Test Ep. 1/100: Status=SUCCESS, Reward=197.75, Steps=13\n",
      "Test Ep. 21/100: Status=SUCCESS, Reward=199.56, Steps=6\n",
      "Test Ep. 41/100: Status=SUCCESS, Reward=196.32, Steps=15\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "env_test = MyGridWorld(grid_size=GRID_SIZE, render_mode=\"human\") \n",
    "test_agents(env_test, trained_agents, num_test_episodes=100)\n",
    "\n",
    "env.close()\n",
    "env_test.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69702443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MARL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
